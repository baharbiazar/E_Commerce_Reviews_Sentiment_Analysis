{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4a8b1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off warnings \n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "ae7a970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning supplies! \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import spacy\n",
    "\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cd9d59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading data\n",
    "df = pd.read_csv('data/reviews.csv', index_col='Unnamed: 0')\n",
    "\n",
    "# Remove nan text\n",
    "df.dropna(subset=['Review Text'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b1495b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22641, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9830ef69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Clothing ID</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017688</td>\n",
       "      <td>-0.018454</td>\n",
       "      <td>-0.014874</td>\n",
       "      <td>0.044902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.017688</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.029962</td>\n",
       "      <td>0.034208</td>\n",
       "      <td>0.040850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rating</th>\n",
       "      <td>-0.018454</td>\n",
       "      <td>0.029962</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.792568</td>\n",
       "      <td>-0.060984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recommended IND</th>\n",
       "      <td>-0.014874</td>\n",
       "      <td>0.034208</td>\n",
       "      <td>0.792568</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.065923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <td>0.044902</td>\n",
       "      <td>0.040850</td>\n",
       "      <td>-0.060984</td>\n",
       "      <td>-0.065923</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Clothing ID       Age    Rating  Recommended IND  \\\n",
       "Clothing ID                 1.000000  0.017688 -0.018454        -0.014874   \n",
       "Age                         0.017688  1.000000  0.029962         0.034208   \n",
       "Rating                     -0.018454  0.029962  1.000000         0.792568   \n",
       "Recommended IND            -0.014874  0.034208  0.792568         1.000000   \n",
       "Positive Feedback Count     0.044902  0.040850 -0.060984        -0.065923   \n",
       "\n",
       "                         Positive Feedback Count  \n",
       "Clothing ID                             0.044902  \n",
       "Age                                     0.040850  \n",
       "Rating                                 -0.060984  \n",
       "Recommended IND                        -0.065923  \n",
       "Positive Feedback Count                 1.000000  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5f1d9272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This top is so much better in person. i do not agree with some of the other reviews about the fabric being scratchy. it is not and i have sensitive skin. i love this top and have got lots of compliments.'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Review Text'].iloc[150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "0610096a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corpus\n",
    "corpus = df[['Review Text']].values.tolist()\n",
    "corpus = [''.join(element) for element in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "04456bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Love this dress!  it\\'s sooo pretty.  i happened to find it in a store, and i\\'m glad i did bc i never would have ordered it online bc it\\'s petite.  i bought a petite and am 5\\'8\".  i love the length on me- hits just a little below the knee.  would definitely be a true midi on someone who is truly petite.'"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "57b89018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#corpus is a list of strings\n",
    "type(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "5dafc391",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stopwords = ['i','me','my','myself','we','our','ours','ourselves','you',\"you're\",\"you've\",\"you'll\",\"you'd\",'your',\\\n",
    "                'yours','yourself','yourselves','he','him','his','himself','she',\"she's\",'her','hers','herself',\\\n",
    "                'it',\"it's\",'its','itself','they','them','their','theirs','themselves','what','which','who','whom',\\\n",
    "                'this','that',\"that'll\",'these','those','am','is','are','was','were','be','been','being','have',\\\n",
    "                'has','had','having','do','does','did','doing' 'a','an','the','and','but','if','or','because','as',\\\n",
    "                'until','while','of','at','by','for','with','about','against','between','into','during','before',\\\n",
    "                'after','to','from','in','out','on','off','over','under','again','further','then','once',\\\n",
    "                'here','there','when','where','why','how','all','any','both','each','few','more','most','other',\\\n",
    "                'some','such','nor','only','own','same','so','than','too','very','s','t','can','will','just','don',\\\n",
    "                \"don't\",'should',\"should've\",'now','d','ll','m','o','re','ve','y','ain','aren',\"aren't\",'couldn',\\\n",
    "                \"couldn't\",'could','a',\"'s\", \"'m\",\\\n",
    "                'didn',\"didn't\",'doesn',\"doesn't\",'hadn',\"hadn't\",'hasn',\"hasn't\",'haven', \"haven't\",'isn',\"isn't\",\\\n",
    "                'ma','mightn',\"mightn't\",'mustn',\"mustn't\",'needn',\"needn't\",'shan',\"shan't\",'shouldn',\"shouldn't\",\\\n",
    "                'wasn',\"wasn't\",'weren',\"weren't\",'won',\"won't\",'wouldn',\"wouldn't\", 'would']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8f1a928f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\\'\\''"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt = string.punctuation + \"''\"\n",
    "pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a619e18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = {\n",
    "\"ain't\": \"am not / are not\",\n",
    "\"aren't\": \"are not / am not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"isn't\": \"is not\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"weren't\": \"were not\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "554012eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What's the best way to ensure this?\n"
     ]
    }
   ],
   "source": [
    "text=\"What's the best way to ensure this?\"\n",
    "for word in text.split():\n",
    "    if word.lower() in contractions:\n",
    "        text = text.replace(word, contractions[word.lower()])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "699aa6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_nots(docs):\n",
    "    not_docs=[]\n",
    "    for doc in docs:\n",
    "        for word in doc.split():\n",
    "            if word in contractions:\n",
    "                doc = doc.replace(word,contractions[word])\n",
    "        not_docs.append(doc)\n",
    "    return not_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "4eb3bb89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I ordered this in carbon for store pick up, and had a ton of stuff (as always) to try on and used this top to pair (skirts and pants). everything went with it. the color is really nice charcoal with shimmer, and went well with pencil skirts, flare pants, etc. my only compaint is it is a bit big, sleeves are long and it doesn't go in petite. also a bit loose for me, but no xxs... so i kept it and wil ldecide later since the light color is already sold out in hte smallest size...\""
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "c5d1e47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_w_nots = clean_nots(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "d92abdee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Absolutely wonderful - silky and sexy and comfortable',\n",
       " 'Love this dress!  it\\'s sooo pretty.  i happened to find it in a store, and i\\'m glad i did bc i never would have ordered it online bc it\\'s petite.  i bought a petite and am 5\\'8\".  i love the length on me- hits just a little below the knee.  would definitely be a true midi on someone who is truly petite.']"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_w_nots[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "76043a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tokens(docs):\n",
    "    ''' returns a list of lists: the clean tokens of docs'''\n",
    "    docs_tokens=[]\n",
    "    for doc in docs:\n",
    "        clean_tokens = []\n",
    "        tokens = word_tokenize(doc)\n",
    "        for token in tokens:\n",
    "            if token.lower() not in my_stopwords and token not in pt:\n",
    "                clean_tokens.append(token.lower())\n",
    "        docs_tokens.append(clean_tokens)    \n",
    "    return docs_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "da148eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_tokens = clean_docs(corpus_w_nots)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "991b860c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['absolutely', 'wonderful', 'silky', 'sexy', 'comfortable']"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#c_tokens is a list of token lists for each document\n",
    "c_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "1c7722ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['absolutely', 'wonderful', 'silky', 'sexy', 'comfortable']"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])(\" \".join(c_tokens[0]))\n",
    "#\" \".join(c_tokens[0])\n",
    "[token.lemma_ for token in nlp if token.pos_ in allowed_postags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "da5d693a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])(\" \".join(c_tokens[0]))\n",
    "type(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "d0451288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "    tokens_out = []\n",
    "    for lst in texts:\n",
    "        doc = nlp(\" \".join(lst)) \n",
    "        tokens_out.append([token.lemma_ for token in doc if token.lemma != 'not' and token.pos_ in allowed_postags])\n",
    "    return tokens_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "417330d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatizing\n",
    "tokens_lemmatized= lemmatization(c_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "05b596ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x7f883fc6d080>"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams(c_tokens[0:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1b5385",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_object = TextBlob(corpus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
