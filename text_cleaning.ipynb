{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10d45647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off warnings \n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "d1cc032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning supplies! \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import spacy\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54e0aed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading data\n",
    "df = pd.read_csv('data/reviews.csv', index_col='Unnamed: 0')\n",
    "\n",
    "# Remove nan text\n",
    "df.dropna(subset=['Review Text'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39370fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22641, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d3cb4d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Clothing ID</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017688</td>\n",
       "      <td>-0.018454</td>\n",
       "      <td>-0.014874</td>\n",
       "      <td>0.044902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.017688</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.029962</td>\n",
       "      <td>0.034208</td>\n",
       "      <td>0.040850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rating</th>\n",
       "      <td>-0.018454</td>\n",
       "      <td>0.029962</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.792568</td>\n",
       "      <td>-0.060984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recommended IND</th>\n",
       "      <td>-0.014874</td>\n",
       "      <td>0.034208</td>\n",
       "      <td>0.792568</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.065923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <td>0.044902</td>\n",
       "      <td>0.040850</td>\n",
       "      <td>-0.060984</td>\n",
       "      <td>-0.065923</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Clothing ID       Age    Rating  Recommended IND  \\\n",
       "Clothing ID                 1.000000  0.017688 -0.018454        -0.014874   \n",
       "Age                         0.017688  1.000000  0.029962         0.034208   \n",
       "Rating                     -0.018454  0.029962  1.000000         0.792568   \n",
       "Recommended IND            -0.014874  0.034208  0.792568         1.000000   \n",
       "Positive Feedback Count     0.044902  0.040850 -0.060984        -0.065923   \n",
       "\n",
       "                         Positive Feedback Count  \n",
       "Clothing ID                             0.044902  \n",
       "Age                                     0.040850  \n",
       "Rating                                 -0.060984  \n",
       "Recommended IND                        -0.065923  \n",
       "Positive Feedback Count                 1.000000  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "686c2d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This top is so much better in person. i do not agree with some of the other reviews about the fabric being scratchy. it is not and i have sensitive skin. i love this top and have got lots of compliments.'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Review Text'].iloc[150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "256fecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corpus\n",
    "corpus = df[['Review Text']].values.tolist()\n",
    "corpus = [''.join(element) for element in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "f733950f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Love this dress!  it\\'s sooo pretty.  i happened to find it in a store, and i\\'m glad i did bc i never would have ordered it online bc it\\'s petite.  i bought a petite and am 5\\'8\".  i love the length on me- hits just a little below the knee.  would definitely be a true midi on someone who is truly petite.'"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "758bc103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#corpus is a list of strings\n",
    "type(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "f2faa430",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stopwords = ['i','me','my','myself','we','our','ours','ourselves','you',\"you're\",\"you've\",\"you'll\",\"you'd\",'your',\\\n",
    "                'yours','yourself','yourselves','he','him','his','himself','she',\"she's\",'her','hers','herself',\\\n",
    "                'it',\"it's\",'its','itself','they','them','their','theirs','themselves','what','which','who','whom',\\\n",
    "                'this','that',\"that'll\",'these','those','am','is','are','was','were','be','been','being','have',\\\n",
    "                'has','had','having','do','does','did','doing' 'a','an','the','and','but','if','or','because','as',\\\n",
    "                'until','while','of','at','by','for','with','about','against','between','into','during','before',\\\n",
    "                'after','to','from','in','out','on','off','over','under','again','further','then','once',\\\n",
    "                'here','there','when','where','why','how','all','any','both','each','few','more','most','other',\\\n",
    "                'some','such','nor','only','own','same','so','than','too','very','s','t','can','will','just','don',\\\n",
    "                \"don't\",'should',\"should've\",'now','d','ll','m','o','re','ve','y','ain','aren',\"aren't\",'couldn',\\\n",
    "                \"couldn't\",'could','a',\"'s\", \"'m\",\\\n",
    "                'didn',\"didn't\",'doesn',\"doesn't\",'hadn',\"hadn't\",'hasn',\"hasn't\",'haven', \"haven't\",'isn',\"isn't\",\\\n",
    "                'ma','mightn',\"mightn't\",'mustn',\"mustn't\",'needn',\"needn't\",'shan',\"shan't\",'shouldn',\"shouldn't\",\\\n",
    "                'wasn',\"wasn't\",'weren',\"weren't\",'won',\"won't\",'wouldn',\"wouldn't\", 'would']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4c60e2e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\\'\\''"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt = string.punctuation + \"''\"\n",
    "pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4631125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = {\n",
    "\"ain't\": \"am not / are not\",\n",
    "\"aren't\": \"are not / am not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"isn't\": \"is not\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"weren't\": \"were not\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79441841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What's the best way to ensure this?\n"
     ]
    }
   ],
   "source": [
    "text=\"What's the best way to ensure this?\"\n",
    "for word in text.split():\n",
    "    if word.lower() in contractions:\n",
    "        text = text.replace(word, contractions[word.lower()])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "98d5d04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_nots(docs):\n",
    "    not_docs=[]\n",
    "    for doc in docs:\n",
    "        for word in doc.split():\n",
    "            if word in contractions:\n",
    "                doc = doc.replace(word,contractions[word])\n",
    "        not_docs.append(doc)\n",
    "    return not_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "98c3b15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I ordered this in carbon for store pick up, and had a ton of stuff (as always) to try on and used this top to pair (skirts and pants). everything went with it. the color is really nice charcoal with shimmer, and went well with pencil skirts, flare pants, etc. my only compaint is it is a bit big, sleeves are long and it doesn't go in petite. also a bit loose for me, but no xxs... so i kept it and wil ldecide later since the light color is already sold out in hte smallest size...\""
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "fff173bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_w_nots = clean_nots(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "651838d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Absolutely wonderful - silky and sexy and comfortable',\n",
       " 'Love this dress!  it\\'s sooo pretty.  i happened to find it in a store, and i\\'m glad i did bc i never would have ordered it online bc it\\'s petite.  i bought a petite and am 5\\'8\".  i love the length on me- hits just a little below the knee.  would definitely be a true midi on someone who is truly petite.']"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_w_nots[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "c5b303ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tokens(docs):\n",
    "    ''' returns a list of lists: the clean tokens of docs'''\n",
    "    docs_tokens=[]\n",
    "    for doc in docs:\n",
    "        clean_tokens = []\n",
    "        tokens = word_tokenize(doc)\n",
    "        for token in tokens:\n",
    "            if token.lower() not in my_stopwords and token not in pt:\n",
    "                clean_tokens.append(token.lower())\n",
    "        docs_tokens.append(clean_tokens)    \n",
    "    return docs_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "46c9fc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_tokens = clean_docs(corpus_w_nots)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "f99527ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#c_tokens is a list of token lists for each document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "da696db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    \n",
    "    nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "    tokens_out = []\n",
    "    for lst in texts:\n",
    "        doc = nlp(\" \".join(lst)) \n",
    "        lemma_tokens=[]\n",
    "        for token in doc:\n",
    "            if token.text == 'not':\n",
    "                lemma_tokens.append(token.text)\n",
    "            else:\n",
    "                if token.pos_ in allowed_postags:\n",
    "                    lemma_tokens.append(token.lemma_)\n",
    "        tokens_out.append(lemma_tokens)\n",
    "    return tokens_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "7b0a4d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['order', 'carbon', 'not', 'scare'], ['kitty', 'kitty', 'not']]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial = [['ordered','carbon','not','scared'], ['hello', 'kitty', 'kitties', 'not']]\n",
    "lemmatization(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "463573e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatizing\n",
    "tokens_lemmatized= lemmatization(c_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "e81709c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokens_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "2032d805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['order',\n",
       " 'carbon',\n",
       " 'store',\n",
       " 'pick',\n",
       " 'ton',\n",
       " 'stuff',\n",
       " 'always',\n",
       " 'try',\n",
       " 'use',\n",
       " 'top',\n",
       " 'pair',\n",
       " 'skirt',\n",
       " 'pant',\n",
       " 'go',\n",
       " 'color',\n",
       " 'really',\n",
       " 'nice',\n",
       " 'charcoal',\n",
       " 'shimmer',\n",
       " 'go',\n",
       " 'well',\n",
       " 'pencil',\n",
       " 'skirt',\n",
       " 'flare',\n",
       " 'pant',\n",
       " 'compaint',\n",
       " 'bit',\n",
       " 'big',\n",
       " 'sleeve',\n",
       " 'long',\n",
       " 'not',\n",
       " 'go',\n",
       " 'petite',\n",
       " 'also',\n",
       " 'bit',\n",
       " 'loose',\n",
       " 'xxs',\n",
       " 'keep',\n",
       " 'wil',\n",
       " 'ldecide',\n",
       " 'later',\n",
       " 'light',\n",
       " 'color',\n",
       " 'already',\n",
       " 'sell',\n",
       " 'small',\n",
       " 'size']"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_lemmatized[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "4535a7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(tokens_lemmatized, min_count=1) # higher threshold fewer phrases.\n",
    "\n",
    "#trigram = gensim.models.Phrases(bigram[data_words], threshold=3)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "#trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "#print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "3bc4d3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "c9b9d7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words_bigrams = make_bigrams(tokens_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "3372dafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I ordered this in carbon for store pick up, and had a ton of stuff (as always) to try on and used this top to pair (skirts and pants). everything went with it. the color is really nice charcoal with shimmer, and went well with pencil skirts, flare pants, etc. my only compaint is it is a bit big, sleeves are long and it doesn't go in petite. also a bit loose for me, but no xxs... so i kept it and wil ldecide later since the light color is already sold out in hte smallest size...\""
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "3799d8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram:  ['A', 'class', 'is', 'a', 'blueprint', 'for', 'the', 'object', '.']\n",
      "2-gram:  ['A class', 'class is', 'is a', 'a blueprint', 'blueprint for', 'for the', 'the object', 'object .']\n",
      "3-gram:  ['A class is', 'class is a', 'is a blueprint', 'a blueprint for', 'blueprint for the', 'for the object', 'the object .']\n",
      "4-gram:  ['A class is a', 'class is a blueprint', 'is a blueprint for', 'a blueprint for the', 'blueprint for the object', 'for the object .']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    " \n",
    "# Function to generate n-grams from sentences.\n",
    "def extract_ngrams(data, num):\n",
    "    n_grams = ngrams(nltk.word_tokenize(data), num)\n",
    "    return [ ' '.join(grams) for grams in n_grams]\n",
    " \n",
    "data = 'A class is a blueprint for the object.'\n",
    " \n",
    "print(\"1-gram: \", extract_ngrams(data, 1))\n",
    "print(\"2-gram: \", extract_ngrams(data, 2))\n",
    "print(\"3-gram: \", extract_ngrams(data, 3))\n",
    "print(\"4-gram: \", extract_ngrams(data, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "5376d887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram:  ['A', 'class', 'is', 'a', 'blueprint', 'for', 'the', 'object']\n",
      "2-gram:  ['A class', 'class is', 'is a', 'a blueprint', 'blueprint for', 'for the', 'the object']\n",
      "3-gram:  ['A class is', 'class is a', 'is a blueprint', 'a blueprint for', 'blueprint for the', 'for the object']\n",
      "4-gram:  ['A class is a', 'class is a blueprint', 'is a blueprint for', 'a blueprint for the', 'blueprint for the object']\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    " \n",
    "# Function to generate n-grams from sentences.\n",
    "def extract_ngrams(data, num):\n",
    "    n_grams = TextBlob(data).ngrams(num)\n",
    "    return [ ' '.join(grams) for grams in n_grams]\n",
    " \n",
    "data = 'A class is a blueprint for the object.'\n",
    " \n",
    "print(\"1-gram: \", extract_ngrams(data, 1))\n",
    "print(\"2-gram: \", extract_ngrams(data, 2))\n",
    "print(\"3-gram: \", extract_ngrams(data, 3))\n",
    "print(\"4-gram: \", extract_ngrams(data, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "4a7b08af",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [row + list(map(lambda ng: '-'.join(ng), ngrams(row, 2))) for row in tokens_lemmatized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2355af",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
