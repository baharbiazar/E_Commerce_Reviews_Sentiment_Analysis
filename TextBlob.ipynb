{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "713c3af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off warnings \n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30a13e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_palette(\"Paired\", 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2e52a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review Text  Rating  Recommended\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4            1\n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5            1\n",
       "2  I had such high hopes for this dress and reall...       3            0\n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5            1\n",
       "4  This shirt is very flattering to all due to th...       5            1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## loading data\n",
    "df = pd.read_csv('data/text_df.csv', index_col='Unnamed: 0')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d82bd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.15.3-py2.py3-none-any.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 6.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nltk>=3.1 in /Users/bahar/opt/anaconda3/lib/python3.8/site-packages (from textblob) (3.6.2)\n",
      "Requirement already satisfied: joblib in /Users/bahar/opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.1->textblob) (1.0.1)\n",
      "Requirement already satisfied: regex in /Users/bahar/opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.1->textblob) (2021.4.4)\n",
      "Requirement already satisfied: tqdm in /Users/bahar/opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.1->textblob) (4.59.0)\n",
      "Requirement already satisfied: click in /Users/bahar/opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.1->textblob) (8.0.1)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.15.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4347490f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d54cdd47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.39166666666666666, subjectivity=0.4357142857142857)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testimonial= TextBlob(\"Textblob is amazingly simple to use. What great fun!\")\n",
    "testimonial.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4a01e3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.125, subjectivity=0.45)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testimonial= TextBlob(\"I bigger windows but these are small.\")\n",
    "testimonial.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a80ad164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.339583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.073675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.512891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23481</th>\n",
       "      <td>I was very happy to snag this dress at such a ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.552667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23482</th>\n",
       "      <td>It reminds me of maternity clothes. soft, stre...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.091667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23483</th>\n",
       "      <td>This fit well, but the top was very see throug...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.414286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23484</th>\n",
       "      <td>I bought this dress for a wedding i have this ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.322222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23485</th>\n",
       "      <td>This dress in a lovely platinum is feminine an...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.413889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22641 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Review Text  Rating  Recommended  \\\n",
       "0      Absolutely wonderful - silky and sexy and comf...       4            1   \n",
       "1      Love this dress!  it's sooo pretty.  i happene...       5            1   \n",
       "2      I had such high hopes for this dress and reall...       3            0   \n",
       "3      I love, love, love this jumpsuit. it's fun, fl...       5            1   \n",
       "4      This shirt is very flattering to all due to th...       5            1   \n",
       "...                                                  ...     ...          ...   \n",
       "23481  I was very happy to snag this dress at such a ...       5            1   \n",
       "23482  It reminds me of maternity clothes. soft, stre...       3            1   \n",
       "23483  This fit well, but the top was very see throug...       3            0   \n",
       "23484  I bought this dress for a wedding i have this ...       3            1   \n",
       "23485  This dress in a lovely platinum is feminine an...       5            1   \n",
       "\n",
       "       polarity  \n",
       "0      0.633333  \n",
       "1      0.339583  \n",
       "2      0.073675  \n",
       "3      0.550000  \n",
       "4      0.512891  \n",
       "...         ...  \n",
       "23481  0.552667  \n",
       "23482  0.091667  \n",
       "23483  0.414286  \n",
       "23484  0.322222  \n",
       "23485  0.413889  \n",
       "\n",
       "[22641 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['polarity'] = df['Review Text'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "aaab911b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Rating</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.792568</td>\n",
       "      <td>0.386303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recommended</th>\n",
       "      <td>0.792568</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.320786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polarity</th>\n",
       "      <td>0.386303</td>\n",
       "      <td>0.320786</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Rating  Recommended  polarity\n",
       "Rating       1.000000     0.792568  0.386303\n",
       "Recommended  0.792568     1.000000  0.320786\n",
       "polarity     0.386303     0.320786  1.000000"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ba0265a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It reminds me of maternity clothes. soft, stretchy, shiny material. cut is flattering and drapes nicely. i only found one button to close front... looked awkward. nice long sleeves.\\nnot for me but maybe for others. just ok.'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[23482,'Review Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72f4b9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_868 = pd.read_csv('data/item_868.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f3499521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(414, 11)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_868.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5c8d28",
   "metadata": {},
   "source": [
    "## LDA MODELING\n",
    "### Finding the latent topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb057156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "#import pyLDAvis.gensim  # don't skip this\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "#import logging\n",
    "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "fd40363b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Love this cream sleeveless top....it goes with everything and you can dress '\n",
      " 'it up or down! this will be a go to top all summer long and probably wear '\n",
      " 'thru the fall as well with a layered sweater, if needed. i typically wear '\n",
      " 'small or medium size and got the medium hoping for a little longer length. i '\n",
      " 'am 57, 34c, and overall wt. of approx. 128 lbs...it fits very nicely . thank '\n",
      " 'you retailer!']\n"
     ]
    }
   ],
   "source": [
    "# prepare stopwords\n",
    "\n",
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "\n",
    "\n",
    "# Convert to list\n",
    "data = item_868['Review Text'].values.tolist()\n",
    "\n",
    "#data = item_868[item_868['Rating']<4]['Review Text'].values.tolist()\n",
    "\n",
    "# Remove Emails\n",
    "data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data]\n",
    "\n",
    "# Remove new line characters\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "\n",
    "# Remove distracting single quotes\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
    "\n",
    "pprint(data[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "17154447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I liked the color of this top but i didnt really like the ruffled stitching around the middle. it looks like someone just tacked on the bottom half. i bought this for my daughter and she likes it. i think it is comfortable and a good top to knock around in.',\n",
       " 'The styling of this top is really cute. it fits perfectly on the shoulders and gets bigger at the hem for the baby doll look. my biggest complaint is the quality! its really cheap and feels like the quality i would expect to see at a cheap retailer. it catches lint like crazy and because the hem is just a pearl edge, it curls really badly. i buy quite a bit from here and this is the worst quality item i have seen in a long time. not worth the $$ if paying full price.',\n",
       " 'Like the other reviewer said this top is extremely wide and boxy. it must be pinned in the picture online. its very frustrating when they do that. thank goodness i didnt pay for shipping! for reference, im 52 and 135 pounds and bought the xxs, its going back for sure. im trying to lose baby weight, not trying to look pregnant!',\n",
       " 'I order this shirt because it looked like a shirt you could dress up or down. when i got it the shirt was really wrinkled. therefore, i knew it would have to ironed a lot. it was quite boxy and was shorter in the front then in the back. i didnt realize that this shirt was two different fabrics. overall i think this shirt would be more flattering on a woman that was petite.',\n",
       " 'Top is very wide and flowy. i am petite with large chest so it hung from widest point and was not flattering. would be very cute with the right body shape.',\n",
       " 'Im 5\"0\" and weigh 105 lbs. i purchased the xxs and it was super-wide, and big all over. it looked like a pregnancy top and did not lay as nicely as shown on the model. also, not shown on the model is the front is short and the back is very long. this would work better on a taller person. i just find it odd that a xxs is still too big. the quality of the fabric and the print is good and the lace-up in the back is cute.',\n",
       " 'Glad i got this on sale. it is more yellow than the photo & short. it is also heavy with a sueded interior. would have given more stars if it was less boxy & longer.',\n",
       " 'I loved this color and ordered it online because i thought it would work for both casual and work days dressed up a little. ummmmm, no. its weird and boxy and does not look at all like it does on the model. i think maybe if you have no bust whatsoever and size way down it would look okay. im only a 34b, weigh 110 pounds, 53\" and it made me look huge and awkward. this is going back!',\n",
       " 'I purchased this top on sale and was really excited about the style. it fit great the first time i wore it. i washed it once, according to the care instructions. after washing it in cold water and allowing it to air dry, it was basically ruined. it shrunk up in length widened out about two inches. im pretty bummed about it because it was cute.',\n",
       " 'I wanted to like this top, as i usually adore a cute peplum feature. when i tried it on yesterday in the store, i was disappointed by how wide and bulky is it. i am petite (52\", 110 lbs), and i tried my usual xs. the fabric was substantial and of a high quality, but unfortunately in this design, that became a bad thing as the bottom of the shirt balooned out around me. it was very unflattering and i felt lost in the shirt! definitely try it on for yourself before purchasing.',\n",
       " 'I thought i would love this shirt because it goes along with my style, but i returned it immediately. it runs so large! the colors are faded, and the trim of the shirt curl over, so it looks cheap and frumpy. i do not recommend this! it hits in all the wrong places.',\n",
       " 'This is a cute top but the fit is problematic. it runs small on top especially around the bust and sleeves but then it flares below the waist in a billowy and unflattering way with way too much fabric. i got both an xsp and an xxsp. the xxsp fit better on bottom but i could hardly pull my arms through the sleeves. both are going back unfortunately. for reference im 5 103 lbs 32b.',\n",
       " 'I really wanted to love this top. i got it in xs in peach. the color is beautiful. i wish they had this exact same color in the boardwalk stroll top. the v neck was way too low and i dont want to have to wear a tank underneath. i would be willing to try an xxs but its been sold out for awhile now and looks like its not coming back. if the size were smaller, v neck higher up, and the top portion of the dress more fitted, it would be the perfect tee!',\n",
       " 'Looks great on the model, but in actuality there is way too much fabric; what should be flowy and billowy looks like a tent (or a maternity top on a petite woman). it didnt matter which size, they all fit me disastrously. i love the look and i thought of keeping it and having it taken in, but theres too much fabric under the chest to make it an easy cut/alteration on the side seams. sometimes i wonder who comes up with these patterns, and if they pin the shirts back on the models. if you put a',\n",
       " 'I am all for a cute flowy tee but this one felt like i was swimming a bit. if youre a true xs, id skip this one. however, if you are able to size down i think it would look really great!',\n",
       " 'I had been eyeing this top for weeks. its look so beautiful on the model, however, not great on me. material is fab. the tee is way shorter than it appears online and there is too much flutter material.',\n",
       " 'I took a chance on this top because i liked the style. i prefer natural fibers like cotton and linen. this is rayon and spandex. sure, why not at least give it a shot and go outside my box?! if the fabric would have been my preference, it would have been a keeper. i did not like the feel, nor the semi-sheer quality. maybe it would work for you, but not for me. back it went.',\n",
       " 'I love the design of this tunic. it is sewn well, but the fabric is cheap. i disliked the texture of the fabric so much that i returned it.',\n",
       " 'This is literally the most unflattering thing i have ever tried on from retailer. the sleeves are so weird and ugly. they get really fat at the top, like a dolman sleeve, but it looks really strange because they don?t flow into the rest of the top, which is very structured. it made my shoulders look huge even though i have very narrow shoulders. this is not apparent in the model picture at all. the thick black seams at the shoulders are also placed in a really awkward spot which also contri',\n",
       " 'I really wanted to love this top. love the mix of fabrics and patterns. but it is too short for a tunic length. i should have paid attention to other reviews. im about 58 and was not too tight in the bust and shoulders.i have to return because the length isnt right.',\n",
       " 'I was looking forward to this cute top to get me through the winter, but the combination of the very think fabric and boxy shape did not work on my 52\", 130 lb, 34d figure. the one i received also had an open unfinished seam beneath the zipper. i imagine this would be a great top for someone taller.',\n",
       " 'This fabric of this top is gorgeous. however, im 5 5\" and it hits in a really weird spot. right no the point of the hip that you dont want to accentuate. you could wear it with leggings to a casual thing, but i work in an office so its too short to wear with leggings and too long to wear with jeans. sad, i love the top 90% of it.',\n",
       " 'Not at all tapered at waist as suggested here by photos. i have wide shoulders and am slim, and this made me look big all around. i am doubtful a smaller size would correct this- i am 510\" and ordered a medium. also, it curls under a bit at the waist. one nice thing about the cream is that it is not see through. anyway, i purchased this to go with high waisted skirts but am returning.',\n",
       " 'This top is cut too short & wide with too much light material in between. to be truly slimming & flattering, it needs to have more of the rayon/spandex blend, to make it heavier & bouncier. then it would \"hang\" appropriately and \"swing\" and (hopefully) not add pounds to the wearer. unfortunately this top is too lightweight & has too much material. pass.',\n",
       " 'The fabric and style on this swing tee are really nice but be aware it runs really, really large. i downsized on my order because of the style but it wasnt enough. like wearing a tent. i would recommend it but know its very full. i did return it.',\n",
       " 'Thought i would try this as other reviewers loved it and its out of my comfort zone. it looked like a poncho with a baggy tank underneath. not worth the price. the tassels looked a bit worn as well.',\n",
       " 'I am normally a m-l (170 lbs, 54\", 34dd). i ordered this top in a medium knowing it ran big, and it is huge. seriously, i could wear it as a dress. i like the whole loose and comfy top thing, but this is so massive it looks sloppy. im going try and return it for a small. hey, i like that i can wear a small! the green color really is pretty, and its so soft. just need a much smaller size.',\n",
       " 'I ordered this top on line. i wanted to love it, but unfortunately the fit was not for me. i am 59 with a long torso. this top was cut very wide and looks like a maternity top.',\n",
       " 'Im 57\", 135 lbs, slender bone structure. the medium fit well in the front but hung to the back of knees in back...just way too long. it would work best on someone closer to 6 tall.',\n",
       " 'This shirt is adorable. but...it didnt work for me! im a smaller gal with a large chest (54\", 34g). i tried on the small, since it seemed so flowy and large. the sleeves were tight, yet the back of the shirt flowed way too much, making the shirt look huge on me. perhaps a more fitted back, and i would have been in love. love the blue color!',\n",
       " 'Unfortunately this top looks billowy and boxy on my. i am tall and very slim and i look pregant in this one ;). maybe it works better on somebody more curvy.',\n",
       " 'The material is soft and comfortable and the top of the shirt fits well. when it comes to the bottom part of the shirt theres a lot of extra fabric which makes it balloon out. it made me look much bigger than i am. i ordered a large (normally i wear lg or xl) and its possible a medium would have fit better. unfortunately this shirt had to be returned.',\n",
       " 'Huge with bountiful amounts of extra fullness....not like represented picture. and it snags very easily. i have a 4 mo. old puppy that jumped up on me as i was trying it on and snagged it in several places. im going to see about returning it with the snags.',\n",
       " 'This is one of the lowest quality shirts i have ever received from retailer. i was so excited for the shirt, it looked so pretty and soft in the pictures. the flax is very scratchy, marring the softness of the rest of the fabric. the top half is totally sheer, requiring a cami. the shirt is cut in such a way that it flares out from the rib cafe in an unstructured way, unnecessarily adding visual pounds. finally, the sewing is done very poorly and the the side tag is literally three inches long--wh',\n",
       " 'Bought in white. it has a ribbed detail that makes ir only for casual wear. the white is pretty sheer. will return.',\n",
       " 'Cute. i love the button back detail. but its completely see-through. i could have worked with that by putting a cami underneath, but the arm holes were too tight. didnt look bad, just felt uncomfortable. you cant really tell in the pic, but theres elastic on the arm holes. itll work if you have super skinny arms, but apparently i dont.',\n",
       " 'I ordered the shirt bc it looked soo cute despite the fact many said this shirt was see thru. its true.. had to return it',\n",
       " 'I fell in love instantly...but...upon looking in the mirror, it is 100 percent see through. at least the black is... i love it enough that i am going to try to put a cami underneath. however, that maynt work. the shirt is lovely in and of itself, but at 48, i dont need a see through shirt. it is also defiantly about a size larger that expected. so size down. almost so good!',\n",
       " 'Purchased this in two colors online. purchased in an xs - i am usually a s or xs. the fit was really large in the xs and the seam on the front of the top was in the wrong place and was really unflattering. returning both.',\n",
       " 'I want to like this top because the idea is cute but i ordered the small and it might have well been xxxl. with sizing like this, one size fits all could just about do it.',\n",
       " 'While i love the green color and the soft waffle knit of this top it was so wide i could have fit two of me standing side by side into it! i mean it was truly laughable! dont know what the manufacturer was thinking but this one needs to go back to the drawing board.',\n",
       " 'Color is pretty true to pic, a bright blue red. sleeves have more volume than pic. so does the body. in my opinion. maybe if i looked like the model. i wear a 27 in jeans and it doesnt look so cute on me. also im a brunette. angles? pinning? i have to wonder. probably just pics at good angles. it looks really cute on the model though.',\n",
       " 'Cute top, not great on me. beautiful, bright color.',\n",
       " 'This top is very beautiful and the color is a dream, but wow is it short! im 58\" and it barely hit the top of the waistband on my jeans. the fabric is oddly heavy and not light and airy like i expected. it seemed like an odd choice for a blouse. because of the seaming and gathered fabric at the top of this shirt, i wouldnt recommend this to women who are busty/curvy on top. it made my chest look huge! this styling may work for petite ladies, but tall & curvy ladies beware.',\n",
       " 'I had high hopes with the other positive reviews, but it didnt work on me. nice stretchy fabric and nice length but it was bunchy in the front and didnt lay well, and didnt do my bust any favors. maybe better on those less pear shaped. hopeless on me.',\n",
       " 'I ordered my normal size and found that this top runs large. i wanted to tie the front ties tighter to accentuate my waist, but even so it was still quite loose. the fabric is very stretchy and thin, and the top was longer on me than pictured in the model. for reference, i am 5-7\" 155lbs, usually wear a medium/8 in a top. this medium was too large.',\n",
       " 'This one will be going back. the color is really blah and the fabric wasnt a texture i was expecting--it is kind of thick and ribbed and i suspect it would stretch out over the course of the day. overall, the cut and style is cute, but i just felt like i was wearing a hospital gown with the combination of the fabric and the style. this may have been cute in a more vibrant color and lighter weight fabric.',\n",
       " 'This top had potential, but the cut is very boxy and not fitted at all like the front picture shows. the picture from the back is much more representative of what it looks like. im 57\", 135lbs and normally wear either an xs or s and the xs in this was still huge and boxy, but very short with tight sleeves (i have small arms so hardly ever have an issue with tight sleeves). the small fit better as far as length and and sleeves, but still very boxy. the pattern and cutouts are very cute, but thi',\n",
       " 'I love the idea of this top and ordered it in white. it is a great design and proportion is nice with jeans. the front is off white t shirt material with a pocket and the back is a light grey heathered panel. i am returning it as it is very thin and the quality is cheap looking. if the grade of material had been a bit thicker and better made, then it would have been a winner!',\n",
       " 'I should have listened to the reviews that said this top was too boxy, but i didnt believe them and bought it anyway. i was wrong! this top is so boxy and wide, just awful.',\n",
       " 'I ordered one of each color in size xl. the fit is true to size. it matches the models photos. theres a lot of material so its flowy. but, it shrunk with air-drying. the colors are very pretty in person. the white is bright. i decided to keep mine even though theyre truthfully, unflattering to wear. the way the sleeves are slightly gathered and cut, make my shoulders & arms look huge. i dont have the shape to pull this off. but, for wearing at home in the summer, theyre worth having. the m',\n",
       " 'I tried on this shirt in the small and the xxs - both were ridiculously wide. they were also both cut really short - the peplum basically started right below my boobs, though the small was maybe a little bit longer than the eex. the stripes are really cute, the cut is just very strange. for reference, the black and white is the small, the taupe is the xxs.',\n",
       " 'Bought this shirt because i loved the cut and the stripes. had little to no shape to it. some may think it runs big but it appears that is the look this top is going for. i feel like being short, i just looked kind of dumpy on me. fabric is nice but borders on see through. it was just ok....nothing exciting.',\n",
       " 'This shirt runs large. i ordered it before it was sold in stores so i didnt return it. the style is really cute. the shirt does pill.',\n",
       " 'I ordered this in tan and white, but ended up returning it. the material is a bit thin (but soft). the shape of the top was decent, i didnt think it was too boxy but i didnt like how the seams looked on the sides. ultimately i didnt think it was worth the price.',\n",
       " 'This is just okay for me. the top is soft and surprisingly flattering, especially from the side, but the front rides up and the neckline never lays flat. it washes well and the tan/white combo is cute, but a little transparent.',\n",
       " 'Gorgeous sleeves, flattering neckline...and a voluminous torso. i loved the fit of the top portion so much, i decided to buy it, knowing it would require alteration. the seamstress removed a *significant* amount of bulk and added vintage buttons to clasp the inverted pleat. i find many of these \"easy breezy\" tops create a shapeless look. extra volume in both the front and back creates a needlessly rotund profile. despite excellent posture, i looked both hunched and pregnant in the unaltered silh',\n",
       " 'I ordered this in blue, and loved the color. im not typically into the flowing top style, but i tried a few items on my last order, this being one. its unseamed at the bottom, which was my primary reason for returning it - i couldnt see that in the photo online - but if that is your style, this item is good quality, soft, comfortable material, and a great spring or fall blue.',\n",
       " 'The peplum for this time hit me in the middle of my rib cage, not at my natural waist, so it looked very odd when it flared out with the peplum so high up. i am busty so its possible this would not be the case for everyone but i generally can wear peplum tops with no problem. i was disappointed to return it, the fabric was very nice and the concept behind the shirt was a good one.',\n",
       " 'Im 55\" and i think fairly proportioned (120 lbs, 34b) and the peplum hit well above my waist. since having kids im a little obsessive about avoiding any shirt that could double as maternity... and this struck me as one. its a cute too, but once its on i dont feel its very flattering.',\n",
       " 'The fabric is a nice weight knit and the top generally well made. unfortunately, the fit was enormous. ive an athletic build w/ big boobs & normally wear l in retailer tops.',\n",
       " 'I ordered this top online during the mothers day sale, thinking i had found the perfect white staple tank i wanted for summer. i had this top on for barely five seconds before i knew it was going straight back. the quality of the fabric and the overall design are both very good. but the problem is that the top comes with an under-layer up top. this is normally a good thing; extra coverage in a sumer top generally means you ca go braless. the problem is that the top layer of the shirt is so shee',\n",
       " 'Purchased this should in the blue motif in size small. i am usually between a small and medium in shirts, 36c broad shoulders. the fit was fine in the small. however, i had a few issues with the top: 1) the blue motif looked actually like a faded blue (as if it had been washed quite a few times and looked worn), 2) the front mid/bottom section laid strangely and gave me a maternity look, and 3) the back has alot of fabric (see back of tank in white motif) and was very voluminous. for me, it wasn',\n",
       " 'The fit on this shirt is bizarre--it very much resembles a nursing top (but wouldnt actually work for that purpose). the side visible in the picture is nicely draped, but the other side can flap open and is completely different. i tried two different sizes and both were equally unfortunate!',\n",
       " 'This would have been cute if it was more fitted. i am 57 and 125 lbs and the small was too wide. i didnt try the xs because the small was almost too short in the sleeves and so was the length.',\n",
       " 'I think this shirt would be really cute on the right body type, just not mine. im 55, 125 and a 34ddd a couple weeks post partum. thought this could be a good shirt while im nursing bc its flowy but stylish. unfortunately it did nothing for me when i put it on. the cut drew all attention to my big chest---not in a good way--and distracted from my smaller lower half. made me look much bigger and heavier than i actually am. probably good for small chested girls, very tall girls or curvy on the',\n",
       " 'I do not even know where to begin with this product. i ordered a small (i go between small and medium) and felt that would be a good fit. after trying on the shirt, i would have opted for the xxxxxxxxs or whatever the smallest size is. this shirt is very boxy. i know its supposed to have a flow to it, but this shirt is too much. it needs to be taken in. or have a belt wrapped around it. i tried the belt look but it did not look flattering. i found this color to be very blah. overall, i am slig',\n",
       " 'I can usually be counted on to love a pretty top with lace detail and a bit of flow. this one has those qualities but it does not look great on me. perhaps it is too flowy because i am 5?3. or possibly the fabric is too soft a look on me. i did size down as reviewers suggested. maybe one size was not enough :-). i must return it.',\n",
       " 'Huge! normally wear a medium and this was huge and very unflattering.',\n",
       " 'I loved this top when i saw it online, and ordered it right away. however, the fit is way off. i am always a size medium. always. but i was swimming in this and had to return it. even if it had fit, i wasnt thrilled with it. i thought it would be something i could dress up, especially with the lace detail, but instead it looked really frumpy. i would recommend this top as long as you know to order a smaller size and are looking for something a little more casual.',\n",
       " 'I was hoping to love this tunic, but it isnt what i was hoping for. the material is cute, but the piece itself is a little too baggy and just doesnt do anything for my shape. just made me look boxy all around. it felt more like a poncho than a tailored tunic. unfortunately, it has to go back.',\n",
       " 'Im not sure i recommend this shirt but i did purchase the plum yesterday. im always always a m and had to size down to an xs on this one. thats how large it was! even the xs had plenty of room; im 56 145 lbs 36b for reference. the material look like it will stretch out even further but i got it anyway. it was on sale plus 25% off and for that price i can use it for casual days on the weekends. its comfortable on and loved the lace detail.',\n",
       " 'I am 6 and typically wear a size 8-10. i am a rather busty kind of gal (36h), so i usually order larges in tops so that i am sure there is no pull across my chest. i ordered a large in this top in the plum color. when i received the top, i could not stop laughing at how huge it was... the fit in the chest area is fine, but i can wrap the sides around me and tie them into a bow. at least half of the material needs to be removed! despite how huge the top is, it is very cute otherwise! i just mail',\n",
       " 'This shirt is beautiful. it is flowy and light, a perfect piece for transitioning from winter to spring. however, do not follow the washing instructions on the tag. it says you can machine wash, tumble dry low, and despite going one step further and washing on my gentle cycle in cold water and drying it on extra low, it came out of the wash so small that a child could barely wear it. it went from being a tunic to an inappropriate crop top i will never wear again. if you do order, please take the',\n",
       " 'Runs very big. i ordered a l and need a m. unfortunately no medium left! great top with lots of character. hate i missed this cute top',\n",
       " 'I was very pleasantly surprised by the beautiful, intricate threaded material of this shirt! it takes the shirt from a casual top to an intricate and unique piece in my closet that can be dressed up or down. the top is definitely larger than i expected - i wear a size small (ordered a small) and its very wide (lots of extra material) as it falls! i checked it to see if i had accidentally received a large when it first came. it looks like a baby doll shirt, with the shirt getting wider and more',\n",
       " 'I had high hopes for this top based on the photos, but when it arrived it is a very thin cheap feeling top. the color is a dusty rose color that has a yellowish mottle throughout it, almost like a tie dye or slub effect. not pretty at all.',\n",
       " 'When i saw this top online, i thought id love it and immediately ordered it in both colors. they arrived today and i am soooo disappointed. i have never seen such drab colors. the blue is a muddy grayish hue (like an overcast day) and the pink is a dusty shade of peach. yuck. and i was hoping the ruffle at the bottom would have a chiffon-like flowy effect. instead, the ruffle is made of a cheap looking knit. back these go...',\n",
       " 'I just received my back-ordered wildberry top in blue. its not blue but instead a dull, mottled purplish hue. it looks like a well-worn, stretched out tee shirt with a tired ruffle along the bottom. so disappointing. its going back for sure.',\n",
       " 'The pink version of this top finally arrived -- nearly 2 months after ordering. the expected delivery date kept slipping. the color is not as shown online. online it looks like a light pink. the actual top was more of taupe color. its a basic tee with pretty ruffling at the bottom. not enough to keep.',\n",
       " 'The fabric is super soft and the grey is pretty, but it is light grey not dark grey as described when you select to buy it. my biggest issue with the top is that the cold shoulder arm reveals the entire arm, so if you arent completely toned with your tricep and all over arm, it will show... which is why i bought this to hide my blunders',\n",
       " 'I love the color (coral/pink) and the open shoulder design of this top, but its too blousy at the bottom (way too much fabric). i ordered a small. i am 54\" and 120 lbs. i might try an xs if they still have them in stock. fabric is comfortable. the ties on the sleeves add a special touch.',\n",
       " 'This top would be great if it were longer and the neck wasnt so open. even for a boatneck, the neck was too wide. for those that dont mind showing their stomachs this top will be okay. the material is nice and stretchy and i like the stripes but just way too short for me.',\n",
       " 'This sweater was pretty short. beyond that, when i raised my arms, the thickness of the sweater caused the shoulders to rise up and stay there when i put my arms down.',\n",
       " 'If you are like me and your shoulders are broader than your hips, the boat-neck on this wont be too wide on you. ---------- i am normally a m or l in retailer tops, and went with the m, and i have very large biceps. if youre broad-shouldered but have smaller arms, i would recommended sizing down a size. ---------- i have a very long torso and didnt find this to be too short...but i love jeans with a 10\" rise. if you are going to pair this with low or medium (8.5\") rise jeans, then yes, you will',\n",
       " 'Cut out design, no seems or hems. very disappointed in retailer',\n",
       " 'Wore it a couple of times, it is cool and comfortable. washed it and the raw edges are starting to fray. i might get one or two more wears out of it. hand washed and hung dry.',\n",
       " 'I sized way down and this top was still shapeless and tent-like. the sweatshirt fabric overpowered the cute, feminine details.',\n",
       " 'Agree with other poster. this shirt runs very big. im all for a flowy, shirt that hides my belly but this is just a tent. ill be retuning it.',\n",
       " 'I loved the criss cross part of this tank. however, it looked so frumpy on. the cut was just odd and if you are petite it felt like a tent. i was so bummed because that criss cross was awesome but it just looked so weird on. i returned it. the material felt nice too.',\n",
       " 'I fell in love with the shirt when i saw it online; but, i was incredibly disappointed with it when it was delivered. on the positive side, the macrame is stunning. once again, there was way too much fabric which makes me look pregnant. most importantly, the color is not peach! its almost a burnt indian red or brick red/orange. it was a disgusting color.',\n",
       " 'I love the teal color of this t-shirt and the macrame design at the top is beautiful, however, the top is way too large. i usually wear a size xs or s in retailer tops, so i ordered the size s, there is so much fabric below the chest it fits like a maternity top. i know if i order an xs, i will have the same problem. below the bust, the top is not flattering and it&amp;#39;s a shame.',\n",
       " 'I tried this top in xs in store. i loved the macrame detail and quality of fabric. it billowed out too much below the chest and looked tent like. my daughter laughed when she saw me in it- so did i! i didnt buy it. im 52\", 115#.',\n",
       " 'I love the material of this shirt and i love the design; however, there is just too much fabric. it felt very boxy and gave me no shape at all. for someone who is petite this just wasnt flattering. i love the design idea though!',\n",
       " 'Lovey top in the photos. however, its fairly large and the chest area can make you look even larger. im 53, 118lbs, 36c. generally wear xs or 2s in retailer tops. ordered the xs but it was just too large and unflattering. the lace work is so pretty. it has potential but the design doesnt work well for some.',\n",
       " 'I normally wear regular s, but even the xsp is too wide on me. it is really maternity wear. also, since the material is thin, the ivory is too shear for my liking.',\n",
       " 'I was excited to receive this tunic in the red (more of a rose color) yet so disappointed to find out how large it runs. my usual size with retailer is a small (sometimes, xs). after reading through the reviews, i ordered an xs and even the xs is too big -- just too much fabric. unfortunately, the xxs is sold out and the xs will be returned.',\n",
       " 'I love tunics and really wanted this to work. i got this in a size s and it is absolutely gigantic. everything else about it is great, and i still havent decided if i will try to swap it for an xs, which is definitely not my usual size (which is usually m, but often s at retailer). the pink/red color was quite pretty. if you have broad hips, fear not - you can size down and this top will still be generous around your hips. basically, if youre deliberating between s and m for this top, get',\n",
       " 'This is a super cute tunic - it is simply way too big.',\n",
       " 'I thought this top would be a little more form fitting than it is. there is so much extra fabric near the bottom it is almost like a swing style top. the fabric will most definitely snag, as it is not a linen or cotton top material but rather a silky type and also very thin - not very good quality. i got the smallest size possible and it was absolutely huge, everywhere but the neck.',\n",
       " 'I loved the rich navy blue color with the accent pockets. the fabric was a nice weight, not too thin like lots of retailer tops. i liked the top from the front, however the back was way too long, especially with the looseness of the style. it would have been much better if it were not so much longer in the back and maybe a little more fitted. it might work on someone taller. im 53\" and 120 lbs. and i tried xs.',\n",
       " 'I want to love this shirt, i really do, but its huge! the top is tent-like, which would be adorable with skinny jeans, however the length of the back dips so low, the top kind of reminds me of pajamas. the color is beautiful, more like a light grey heather, and the white piping is like a shimmery ribbon material. overall, the top is cute, but it dips too low in the back and the bow weighs down the back of the shirt, so it makes it hard to adjust it in the front. sadly, its a return.',\n",
       " 'Like the idea of this shirt so much. but the neckline was still way too low- the top of my bra was visible. wishing the under layer really covered as no way im going to another layer to an already layered shirt. might just be my body type, so might work for someone else, but sending back.',\n",
       " 'Interesting, slightly transparent fabric. neckline is not so open as pictured. body is boxier than pictured. would recommend as a maybe.',\n",
       " 'I really wanted to like this because the color is beautiful and the knit is obviously good quality. but the shape is impossible to work with. it doesnt just run big, it just hangs there. really disappointing. itll have to go back.',\n",
       " 'Do not buy! i used my 15% discount on this. what a waste. my usual sizes range from s to l depending on what brand. i should have gotten a small. i dont think that wouldve helped. it was so awkward looking. nothing like the model. it made me look as if i had gained 15 pounds. it was waaay longer in the back-like a mullet. the material was really thick. it is more appropriate for fall. i had high hopes for this-to dress up or down. it was just so ridiculous.',\n",
       " 'I ordered this since it looked so cute on the model . when i it arrived, i was excited to try it on, but when i did...blah. the color is murky and the top runs large, not to mention that the material is too heavy for a short sleeved top (plus its lined). i really wanted to like it and debated wetting it and then putting it in the dryer to shrink it a bit. in the end, i decided that it wasnt worth it. too bad, as the concept was a good one. it just failed in the execution.',\n",
       " 'The way the back came down so much made the top look weird. i do like some tops that hang longer in the back but this one was just too much. also the material was kind of blah it was thick polyester which would not be very cool during the summer and the color looked better in the picture. so to me it was just a over priced odd top.',\n",
       " 'I like the color blocking of this top, but it was too large and billowy on the bottom. it felt like a pregnancy top so i had to return it as it gave me no shape.',\n",
       " 'This is a beautiful top but the xs was literally 4-6 inches too wide. very disappointing! i am thin and tall but this was a maternity top on me. i dont usually wear xxs. it is much more voluminous than it appears in the picture and it is definitely gray and blue not white.',\n",
       " 'I get that its a swing style top and supposed to be loose but it looked so much bigger on me than on the model and just not flattering at all.',\n",
       " 'If youre pregnant, congratulations. this shirt is for you. if youve ever dreamed of being an xxs, this shirt is also for you. im a 34d, normally a small or medium, but often size down to xs in swing tops. the xs is ginormous on me, although it fits through the shoulders. i can hold onto the bottom and stretch my arms straight out at the sides, its that wide. think flying squirrel. what doesnt show in the pictures is that it also has a slight dolman sleeve, which makes it look wide at the to',\n",
       " 'Theres just nothing special about it. it runs small and the fabric is itchy. the design with button caught my eye, but i didnt like it well enough to keep it.',\n",
       " 'The blouse looked better on the model. i liked the way it fit, just not how it looks. the fabric made me itch, which was one of the other reasons i returned it. i wished it had looked good and the fabric didnt make me itch. i really liked the unique look to the shirt.',\n",
       " 'This is a rare review for me, i usually love my retailer purchases, even at times when other reviewers arent fans, but this top is terrible. 54\" 103, 32 b for reference, small frame, athletic, bought the xs in black. the length could have been longer, but i could have lived with the length. the arm hole area, however, a different story. because its boxy, and the fabric is stiffer bc of the large flowers, the top sticks out on the sides under the arm holes leaving a gape, it did not fit snuggly',\n",
       " 'Just a ginormous, shapeless shirt. runs extremely large. i am normally a medium to large in shirts and the medium was huge. i can only imagine an xs would work and i am no xtra small!',\n",
       " 'I really loved the way this shirt looked on me. its forgiving and flattering, and really lightweight. the fabric, however, couldnt even withstand half a days wear without snagging 3 times and developing a hole right in the center. i have no idea how this happened, as i wasnt wearing or near anything that could have pulled at it. such a shame. this could have been a staple wardrobe piece for me.',\n",
       " 'I got this shirt and loved it so much the first time i wore it. it swings well and is an easy basic that looks great. however, after i washed it the first time, it became clingy and stuck to me and doesnt lie right. its such a shame because i was thrilled with this as an addition to my wardrobe!',\n",
       " 'I loved the materials texture and drape, but it was too sheer for me. i am 100% against having to wear a tank under white tees. (which means i have a lot of trouble finding any white tees, but...) other than the see-through nature, i loved this shirt!',\n",
       " 'I agree that this shirt is boxy and has no shape; it doesnt look at all like it does on the model. i returned it.',\n",
       " 'I was excited to see this top on sale as i had been watching it for a few weeks. unfortunately, i was very disappointed when i received it. it is, as a previous person said, very much like a pajama top. it is very loose and boxy, and in my opinion, did not flatter my shape at all. sadly, i will be returning it. i would not recommend this top to a person who is athletic, or straight and slender, as you suggest.',\n",
       " 'Hi, when i received this top i tried it on, looked in the mirror and packed it up for a return. the quality is excellent but it just too boxy. fits nothing like it appears on the model.',\n",
       " 'Cute stripes and soft, but very pajama top like in feel/look... like if you wear it out, people will assume youve got the matching bottoms stuck under your pillow at home.',\n",
       " 'I really wanted to love this but the cut was very wide, short, and crooked. after it was washed once, it was completely unwearable because it hung all wrong.',\n",
       " 'I wanted to love this shirt, but was very disappointed. i had read other reviews and still ordered, but wish i would have listened. the shirt looks nothing like photos online and is extremely boxy and unflattering. had to send it back.',\n",
       " 'I love baseball style tees and when i saw the homebase tee (in two colors no less), i was very thrilled especially since it was during the 20% mothers day promotion on all items. based on the models photos, the top looks flattering with a swing type style. i usually wear a medium and bought a small size in this top. when the package was delivered, i excitedly opened it and found two tees looking like maternity tops which would be lovely if i was pregnant. the tops are so wide not like the webs',\n",
       " 'I bought this shirt after reading so many positive reviews. it looks much thinner and cheaper than the photo depicts. like many reviewers have said, it does hit just above midriff but the fringe covers your belly. it didn&#39;t hang right on me and i felt like i was wearing a rug.',\n",
       " 'I love baseball tees and this looked like a more refined version, but it was huge and shapeless. nice material and fabric but this one is going back.',\n",
       " 'Hi, i would have to agree with all of the reviewers.i unfortunately had to find out for myself. mistake. its huge. i love the quality and design but even if you sized down two sizes it wouldnt help.',\n",
       " 'I loved this sweater when i bought it. wore it a couple times then washed it according to the tag. it shrunk at least two sizes! and the tassels got all tangled (which i guess i should have seen coming). pretty bummed about it because this sweater looked beautiful on.',\n",
       " 'I love the look of this sweater, but just bought and put on at home and noticed 2 pea sized holes in fabric, near arm holes, but not on seams. not sure if i bought this way and did not notice or if fabric is just incredibly delicate. will try to repair but scated this will not hold up... look it over carefully before you buy, they kind of look like moth holes...',\n",
       " 'I had such high hopes for this shirt! i got it in both the black and moss (which is a beautiful color). however, the ruffle was just too big. i put it on and immediately felt like a circus clown. it would probably be beautiful on a woman with a more straight figure with fewer curves, but on me, it was not flattering at all.',\n",
       " 'Cute design for a casual top. however it was a little snug on the bust for a medium. i returned it']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7492aaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['love', 'this', 'cream', 'sleeveless', 'top', 'it', 'goes', 'with', 'everything', 'and', 'you', 'can', 'dress', 'it', 'up', 'or', 'down', 'this', 'will', 'be', 'go', 'to', 'top', 'all', 'summer', 'long', 'and', 'probably', 'wear', 'thru', 'the', 'fall', 'as', 'well', 'with', 'layered', 'sweater', 'if', 'needed', 'typically', 'wear', 'small', 'or', 'medium', 'size', 'and', 'got', 'the', 'medium', 'hoping', 'for', 'little', 'longer', 'length', 'am', 'and', 'overall', 'wt', 'of', 'approx', 'lbs', 'it', 'fits', 'very', 'nicely', 'thank', 'you', 'retailer']]\n"
     ]
    }
   ],
   "source": [
    "# tokenizing and cleaning the text\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "15a84f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['love_this', 'cream', 'sleeveless', 'top', 'it_goes', 'with', 'everything', 'and', 'you_can', 'dress', 'it', 'up_or_down', 'this', 'will_be', 'go', 'to', 'top', 'all', 'summer', 'long', 'and', 'probably', 'wear', 'thru', 'the', 'fall', 'as_well', 'with', 'layered', 'sweater', 'if', 'needed', 'typically_wear', 'small', 'or_medium', 'size', 'and', 'got_the', 'medium', 'hoping', 'for', 'little', 'longer', 'length', 'am', 'and', 'overall', 'wt', 'of', 'approx', 'lbs', 'it_fits', 'very', 'nicely', 'thank', 'you', 'retailer']\n"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=2, threshold=3) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=3)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "98b3b70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f7528d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['love', 'cream', 'sleeveless', 'top', 'go', 'dress', 'go', 'top', 'summer', 'long', 'probably', 'wear', 'fall', 'well', 'layer', 'sweater', 'need', 'typically_wear', 'small', 'medium', 'size', 'get', 'medium', 'hope', 'little', 'long', 'length', 'overall', 'fit', 'nicely', 'thank', 'retailer']]\n"
     ]
    }
   ],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "#python3 -m spacy download en\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "#nlp = spacy.load('en_core_web_trf', disable=['parser', 'ner'])\n",
    "\n",
    "#import en_core_web_trf\n",
    "#nlp = en_core_web_trf.load()\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "63f5e9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(24, 2), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 2), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8068b392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('cream', 1),\n",
       "  ('dress', 1),\n",
       "  ('fall', 1),\n",
       "  ('fit', 1),\n",
       "  ('get', 1),\n",
       "  ('go', 2),\n",
       "  ('hope', 1),\n",
       "  ('layer', 1),\n",
       "  ('length', 1),\n",
       "  ('little', 1),\n",
       "  ('long', 2),\n",
       "  ('love', 1),\n",
       "  ('medium', 2),\n",
       "  ('need', 1),\n",
       "  ('nicely', 1),\n",
       "  ('overall', 1),\n",
       "  ('probably', 1),\n",
       "  ('retailer', 1),\n",
       "  ('size', 1),\n",
       "  ('sleeveless', 1),\n",
       "  ('small', 1),\n",
       "  ('summer', 1),\n",
       "  ('sweater', 1),\n",
       "  ('thank', 1),\n",
       "  ('top', 2),\n",
       "  ('typically_wear', 1),\n",
       "  ('wear', 1),\n",
       "  ('well', 1)]]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "549377e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=8, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=1,\n",
    "                                           passes=20,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "bdb93485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.084*\"big\" + 0.082*\"put\" + 0.079*\"style\" + 0.044*\"really\" + '\n",
      "  '0.041*\"quality\" + 0.037*\"bit\" + 0.022*\"hit\" + 0.020*\"thin\" + 0.019*\"blue\" + '\n",
      "  '0.017*\"sheer\"'),\n",
      " (1,\n",
      "  '0.148*\"look\" + 0.080*\"sweater\" + 0.056*\"online\" + 0.054*\"wide\" + 0.036*\"m\" '\n",
      "  '+ 0.032*\"try\" + 0.026*\"day\" + 0.018*\"store\" + 0.017*\"couple\" + '\n",
      "  '0.017*\"appear\"'),\n",
      " (2,\n",
      "  '0.049*\"make\" + 0.049*\"great\" + 0.045*\"jean\" + 0.044*\"large\" + 0.036*\"low\" + '\n",
      "  '0.034*\"cut\" + 0.030*\"pretty\" + 0.027*\"hope\" + 0.024*\"run\" + 0.020*\"come\"'),\n",
      " (3,\n",
      "  '0.104*\"soft\" + 0.096*\"sleeve\" + 0.080*\"nice\" + 0.056*\"design\" + '\n",
      "  '0.046*\"material\" + 0.031*\"keep\" + 0.029*\"slightly\" + 0.022*\"lbs\" + '\n",
      "  '0.011*\"reference\" + 0.005*\"fringe\"'),\n",
      " (4,\n",
      "  '0.051*\"fit\" + 0.048*\"size\" + 0.036*\"wear\" + 0.033*\"cute\" + 0.028*\"model\" + '\n",
      "  '0.026*\"get\" + 0.025*\"however\" + 0.024*\"black\" + 0.024*\"person\" + '\n",
      "  '0.024*\"back\"'),\n",
      " (5,\n",
      "  '0.140*\"shirt\" + 0.057*\"purchase\" + 0.056*\"order\" + 0.038*\"comfy\" + '\n",
      "  '0.038*\"petite\" + 0.031*\"perfect\" + 0.029*\"straight\" + 0.021*\"work\" + '\n",
      "  '0.019*\"warm\" + 0.013*\"seem\"'),\n",
      " (6,\n",
      "  '0.131*\"top\" + 0.081*\"love\" + 0.034*\"see\" + 0.023*\"tee\" + 0.023*\"beautiful\" '\n",
      "  '+ 0.023*\"much\" + 0.022*\"still\" + 0.021*\"even\" + 0.021*\"show\" + '\n",
      "  '0.020*\"well\"'),\n",
      " (7,\n",
      "  '0.072*\"buy\" + 0.058*\"fabric\" + 0.040*\"side\" + 0.039*\"color\" + 0.038*\"boxy\" '\n",
      "  '+ 0.037*\"photo\" + 0.036*\"way\" + 0.034*\"return\" + 0.027*\"bust\" + '\n",
      "  '0.024*\"say\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c9830ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -8.411911974826841\n",
      "\n",
      "Coherence Score:  0.3803384928583072\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58147158",
   "metadata": {},
   "source": [
    "## Another LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "57ad5fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, nltk, spacy, gensim\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "a177066f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['love cream sleeveless top go dress be go top summer long probably wear fall as well layered sweater need typically wear small medium size get medium hoping little long length overall lb fit very nicely thank retailer', 'like color top do really ruffled stitch middle look just tack bottom half buy daughter like think be comfortable good top knock around']\n"
     ]
    }
   ],
   "source": [
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append(\" \".join([token.lemma_ if token.lemma_ not in ['-PRON-'] else '' for token in doc if token.pos_ in allowed_postags]))\n",
    "    return texts_out\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# Run in terminal: python3 -m spacy download en\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only Noun, Adj, Verb, Adverb\n",
    "data_lemmatized = lemmatization(data_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "1d4ca0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word',       \n",
    "                             min_df=2,                        # minimum reqd occurences of a word \n",
    "                             stop_words='english',             # remove stop words\n",
    "                             lowercase=True,                   # convert all words to lowercase\n",
    "                             token_pattern='[a-zA-Z0-9]{2,}',  # num chars > 3\n",
    "                             # max_features=50000,             # max number of uniq words\n",
    "                            )\n",
    "\n",
    "data_vectorized = vectorizer.fit_transform(data_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "f1236e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsicity:  2.618166704142052 %\n"
     ]
    }
   ],
   "source": [
    "# Materialize the sparse data\n",
    "data_dense = data_vectorized.todense()\n",
    "\n",
    "# Compute Sparsicity = Percentage of Non-Zero cells\n",
    "print(\"Sparsicity: \", ((data_dense > 0).sum()/data_dense.size)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "6d6bb662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LatentDirichletAllocation(batch_size=2, learning_method='online', max_iter=20,\n",
      "                          n_components=5, n_jobs=-1, random_state=100)\n"
     ]
    }
   ],
   "source": [
    "# Build LDA Model\n",
    "lda_model = LatentDirichletAllocation(n_components=5,               # Number of topics\n",
    "                                      max_iter=20,               # Max learning iterations\n",
    "                                      learning_method='online',   \n",
    "                                      random_state=100,          # Random state\n",
    "                                      batch_size=2,            # n docs in each learning iter\n",
    "                                      evaluate_every = -1,       # compute perplexity every n iters, default: Don't\n",
    "                                      n_jobs = -1,               # Use all available CPUs\n",
    "                                     )\n",
    "lda_output = lda_model.fit_transform(data_vectorized)\n",
    "\n",
    "print(lda_model)  # Model attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "bdcde08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Likelihood:  -52542.317445369416\n",
      "Perplexity:  469.21245411531214\n",
      "{'batch_size': 2,\n",
      " 'doc_topic_prior': None,\n",
      " 'evaluate_every': -1,\n",
      " 'learning_decay': 0.7,\n",
      " 'learning_method': 'online',\n",
      " 'learning_offset': 10.0,\n",
      " 'max_doc_update_iter': 100,\n",
      " 'max_iter': 20,\n",
      " 'mean_change_tol': 0.001,\n",
      " 'n_components': 5,\n",
      " 'n_jobs': -1,\n",
      " 'perp_tol': 0.1,\n",
      " 'random_state': 100,\n",
      " 'topic_word_prior': None,\n",
      " 'total_samples': 1000000.0,\n",
      " 'verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "# Log Likelyhood: Higher the better\n",
    "print(\"Log Likelihood: \", lda_model.score(data_vectorized))\n",
    "\n",
    "# Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
    "print(\"Perplexity: \", lda_model.perplexity(data_vectorized))\n",
    "\n",
    "# See model parameters\n",
    "pprint(lda_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "e8300941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LatentDirichletAllocation(),\n",
       "             param_grid={'learning_decay': [0.5, 0.7, 0.9],\n",
       "                         'n_components': [5, 10, 15]})"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid Search\n",
    "# Define Search Param\n",
    "search_params = {'n_components': [5,10, 15], 'learning_decay': [.5, .7, .9]}\n",
    "\n",
    "# Init the Model\n",
    "lda = LatentDirichletAllocation()\n",
    "\n",
    "# Init Grid Search Class\n",
    "model = GridSearchCV(lda, param_grid=search_params)\n",
    "\n",
    "# Do the Grid Search\n",
    "model.fit(data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "53d3ba1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model's Params:  {'learning_decay': 0.7, 'n_components': 5}\n",
      "Best Log Likelihood Score:  -13185.344229351685\n",
      "Model Perplexity:  452.9042039821211\n"
     ]
    }
   ],
   "source": [
    "# Best Model\n",
    "best_lda_model = model.best_estimator_\n",
    "\n",
    "# Model Parameters\n",
    "print(\"Best Model's Params: \", model.best_params_)\n",
    "\n",
    "# Log Likelihood Score\n",
    "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
    "\n",
    "# Perplexity\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(data_vectorized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0a9332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "3e40c54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_37f13_row0_col0,#T_37f13_row0_col1,#T_37f13_row1_col3,#T_37f13_row1_col4,#T_37f13_row1_col5,#T_37f13_row2_col2,#T_37f13_row2_col5,#T_37f13_row3_col0,#T_37f13_row3_col1,#T_37f13_row4_col2,#T_37f13_row4_col3,#T_37f13_row4_col5,#T_37f13_row5_col3,#T_37f13_row5_col5,#T_37f13_row6_col1,#T_37f13_row6_col5,#T_37f13_row7_col0,#T_37f13_row8_col3,#T_37f13_row8_col5,#T_37f13_row9_col1,#T_37f13_row9_col5,#T_37f13_row10_col1,#T_37f13_row10_col5,#T_37f13_row11_col1,#T_37f13_row11_col4,#T_37f13_row11_col5,#T_37f13_row12_col0,#T_37f13_row12_col2,#T_37f13_row13_col4,#T_37f13_row13_col5,#T_37f13_row14_col1,#T_37f13_row14_col5,#T_37f13_row15_col1,#T_37f13_row15_col5,#T_37f13_row16_col0,#T_37f13_row16_col1,#T_37f13_row16_col5,#T_37f13_row17_col3,#T_37f13_row17_col5,#T_37f13_row18_col1,#T_37f13_row18_col5,#T_37f13_row19_col2,#T_37f13_row19_col5{\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }#T_37f13_row0_col2,#T_37f13_row0_col3,#T_37f13_row0_col4,#T_37f13_row0_col5,#T_37f13_row1_col0,#T_37f13_row1_col1,#T_37f13_row1_col2,#T_37f13_row2_col0,#T_37f13_row2_col1,#T_37f13_row2_col3,#T_37f13_row2_col4,#T_37f13_row3_col2,#T_37f13_row3_col3,#T_37f13_row3_col4,#T_37f13_row3_col5,#T_37f13_row4_col0,#T_37f13_row4_col1,#T_37f13_row4_col4,#T_37f13_row5_col0,#T_37f13_row5_col1,#T_37f13_row5_col2,#T_37f13_row5_col4,#T_37f13_row6_col0,#T_37f13_row6_col2,#T_37f13_row6_col3,#T_37f13_row6_col4,#T_37f13_row7_col1,#T_37f13_row7_col2,#T_37f13_row7_col3,#T_37f13_row7_col4,#T_37f13_row7_col5,#T_37f13_row8_col0,#T_37f13_row8_col1,#T_37f13_row8_col2,#T_37f13_row8_col4,#T_37f13_row9_col0,#T_37f13_row9_col2,#T_37f13_row9_col3,#T_37f13_row9_col4,#T_37f13_row10_col0,#T_37f13_row10_col2,#T_37f13_row10_col3,#T_37f13_row10_col4,#T_37f13_row11_col0,#T_37f13_row11_col2,#T_37f13_row11_col3,#T_37f13_row12_col1,#T_37f13_row12_col3,#T_37f13_row12_col4,#T_37f13_row12_col5,#T_37f13_row13_col0,#T_37f13_row13_col1,#T_37f13_row13_col2,#T_37f13_row13_col3,#T_37f13_row14_col0,#T_37f13_row14_col2,#T_37f13_row14_col3,#T_37f13_row14_col4,#T_37f13_row15_col0,#T_37f13_row15_col2,#T_37f13_row15_col3,#T_37f13_row15_col4,#T_37f13_row16_col2,#T_37f13_row16_col3,#T_37f13_row16_col4,#T_37f13_row17_col0,#T_37f13_row17_col1,#T_37f13_row17_col2,#T_37f13_row17_col4,#T_37f13_row18_col0,#T_37f13_row18_col2,#T_37f13_row18_col3,#T_37f13_row18_col4,#T_37f13_row19_col0,#T_37f13_row19_col1,#T_37f13_row19_col3,#T_37f13_row19_col4{\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }</style><table id=\"T_37f13_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Topic0</th>        <th class=\"col_heading level0 col1\" >Topic1</th>        <th class=\"col_heading level0 col2\" >Topic2</th>        <th class=\"col_heading level0 col3\" >Topic3</th>        <th class=\"col_heading level0 col4\" >Topic4</th>        <th class=\"col_heading level0 col5\" >dominant_topic</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_37f13_level0_row0\" class=\"row_heading level0 row0\" >Doc0</th>\n",
       "                        <td id=\"T_37f13_row0_col0\" class=\"data row0 col0\" >0.640000</td>\n",
       "                        <td id=\"T_37f13_row0_col1\" class=\"data row0 col1\" >0.330000</td>\n",
       "                        <td id=\"T_37f13_row0_col2\" class=\"data row0 col2\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row0_col3\" class=\"data row0 col3\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row0_col4\" class=\"data row0 col4\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row0_col5\" class=\"data row0 col5\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_37f13_level0_row1\" class=\"row_heading level0 row1\" >Doc1</th>\n",
       "                        <td id=\"T_37f13_row1_col0\" class=\"data row1 col0\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row1_col1\" class=\"data row1 col1\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row1_col2\" class=\"data row1 col2\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row1_col3\" class=\"data row1 col3\" >0.510000</td>\n",
       "                        <td id=\"T_37f13_row1_col4\" class=\"data row1 col4\" >0.450000</td>\n",
       "                        <td id=\"T_37f13_row1_col5\" class=\"data row1 col5\" >3</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_37f13_level0_row2\" class=\"row_heading level0 row2\" >Doc2</th>\n",
       "                        <td id=\"T_37f13_row2_col0\" class=\"data row2 col0\" >0.020000</td>\n",
       "                        <td id=\"T_37f13_row2_col1\" class=\"data row2 col1\" >0.020000</td>\n",
       "                        <td id=\"T_37f13_row2_col2\" class=\"data row2 col2\" >0.930000</td>\n",
       "                        <td id=\"T_37f13_row2_col3\" class=\"data row2 col3\" >0.020000</td>\n",
       "                        <td id=\"T_37f13_row2_col4\" class=\"data row2 col4\" >0.020000</td>\n",
       "                        <td id=\"T_37f13_row2_col5\" class=\"data row2 col5\" >2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_37f13_level0_row3\" class=\"row_heading level0 row3\" >Doc3</th>\n",
       "                        <td id=\"T_37f13_row3_col0\" class=\"data row3 col0\" >0.570000</td>\n",
       "                        <td id=\"T_37f13_row3_col1\" class=\"data row3 col1\" >0.420000</td>\n",
       "                        <td id=\"T_37f13_row3_col2\" class=\"data row3 col2\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row3_col3\" class=\"data row3 col3\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row3_col4\" class=\"data row3 col4\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row3_col5\" class=\"data row3 col5\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_37f13_level0_row4\" class=\"row_heading level0 row4\" >Doc4</th>\n",
       "                        <td id=\"T_37f13_row4_col0\" class=\"data row4 col0\" >0.000000</td>\n",
       "                        <td id=\"T_37f13_row4_col1\" class=\"data row4 col1\" >0.000000</td>\n",
       "                        <td id=\"T_37f13_row4_col2\" class=\"data row4 col2\" >0.110000</td>\n",
       "                        <td id=\"T_37f13_row4_col3\" class=\"data row4 col3\" >0.870000</td>\n",
       "                        <td id=\"T_37f13_row4_col4\" class=\"data row4 col4\" >0.000000</td>\n",
       "                        <td id=\"T_37f13_row4_col5\" class=\"data row4 col5\" >3</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_37f13_level0_row5\" class=\"row_heading level0 row5\" >Doc5</th>\n",
       "                        <td id=\"T_37f13_row5_col0\" class=\"data row5 col0\" >0.020000</td>\n",
       "                        <td id=\"T_37f13_row5_col1\" class=\"data row5 col1\" >0.020000</td>\n",
       "                        <td id=\"T_37f13_row5_col2\" class=\"data row5 col2\" >0.020000</td>\n",
       "                        <td id=\"T_37f13_row5_col3\" class=\"data row5 col3\" >0.940000</td>\n",
       "                        <td id=\"T_37f13_row5_col4\" class=\"data row5 col4\" >0.020000</td>\n",
       "                        <td id=\"T_37f13_row5_col5\" class=\"data row5 col5\" >3</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_37f13_level0_row6\" class=\"row_heading level0 row6\" >Doc6</th>\n",
       "                        <td id=\"T_37f13_row6_col0\" class=\"data row6 col0\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row6_col1\" class=\"data row6 col1\" >0.960000</td>\n",
       "                        <td id=\"T_37f13_row6_col2\" class=\"data row6 col2\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row6_col3\" class=\"data row6 col3\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row6_col4\" class=\"data row6 col4\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row6_col5\" class=\"data row6 col5\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_37f13_level0_row7\" class=\"row_heading level0 row7\" >Doc7</th>\n",
       "                        <td id=\"T_37f13_row7_col0\" class=\"data row7 col0\" >0.960000</td>\n",
       "                        <td id=\"T_37f13_row7_col1\" class=\"data row7 col1\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row7_col2\" class=\"data row7 col2\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row7_col3\" class=\"data row7 col3\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row7_col4\" class=\"data row7 col4\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row7_col5\" class=\"data row7 col5\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_37f13_level0_row8\" class=\"row_heading level0 row8\" >Doc8</th>\n",
       "                        <td id=\"T_37f13_row8_col0\" class=\"data row8 col0\" >0.030000</td>\n",
       "                        <td id=\"T_37f13_row8_col1\" class=\"data row8 col1\" >0.030000</td>\n",
       "                        <td id=\"T_37f13_row8_col2\" class=\"data row8 col2\" >0.030000</td>\n",
       "                        <td id=\"T_37f13_row8_col3\" class=\"data row8 col3\" >0.880000</td>\n",
       "                        <td id=\"T_37f13_row8_col4\" class=\"data row8 col4\" >0.030000</td>\n",
       "                        <td id=\"T_37f13_row8_col5\" class=\"data row8 col5\" >3</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_37f13_level0_row9\" class=\"row_heading level0 row9\" >Doc9</th>\n",
       "                        <td id=\"T_37f13_row9_col0\" class=\"data row9 col0\" >0.050000</td>\n",
       "                        <td id=\"T_37f13_row9_col1\" class=\"data row9 col1\" >0.800000</td>\n",
       "                        <td id=\"T_37f13_row9_col2\" class=\"data row9 col2\" >0.050000</td>\n",
       "                        <td id=\"T_37f13_row9_col3\" class=\"data row9 col3\" >0.050000</td>\n",
       "                        <td id=\"T_37f13_row9_col4\" class=\"data row9 col4\" >0.050000</td>\n",
       "                        <td id=\"T_37f13_row9_col5\" class=\"data row9 col5\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_37f13_level0_row10\" class=\"row_heading level0 row10\" >Doc10</th>\n",
       "                        <td id=\"T_37f13_row10_col0\" class=\"data row10 col0\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row10_col1\" class=\"data row10 col1\" >0.960000</td>\n",
       "                        <td id=\"T_37f13_row10_col2\" class=\"data row10 col2\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row10_col3\" class=\"data row10 col3\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row10_col4\" class=\"data row10 col4\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row10_col5\" class=\"data row10 col5\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_37f13_level0_row11\" class=\"row_heading level0 row11\" >Doc11</th>\n",
       "                        <td id=\"T_37f13_row11_col0\" class=\"data row11 col0\" >0.030000</td>\n",
       "                        <td id=\"T_37f13_row11_col1\" class=\"data row11 col1\" >0.390000</td>\n",
       "                        <td id=\"T_37f13_row11_col2\" class=\"data row11 col2\" >0.030000</td>\n",
       "                        <td id=\"T_37f13_row11_col3\" class=\"data row11 col3\" >0.030000</td>\n",
       "                        <td id=\"T_37f13_row11_col4\" class=\"data row11 col4\" >0.520000</td>\n",
       "                        <td id=\"T_37f13_row11_col5\" class=\"data row11 col5\" >4</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_37f13_level0_row12\" class=\"row_heading level0 row12\" >Doc12</th>\n",
       "                        <td id=\"T_37f13_row12_col0\" class=\"data row12 col0\" >0.530000</td>\n",
       "                        <td id=\"T_37f13_row12_col1\" class=\"data row12 col1\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row12_col2\" class=\"data row12 col2\" >0.450000</td>\n",
       "                        <td id=\"T_37f13_row12_col3\" class=\"data row12 col3\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row12_col4\" class=\"data row12 col4\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row12_col5\" class=\"data row12 col5\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_37f13_level0_row13\" class=\"row_heading level0 row13\" >Doc13</th>\n",
       "                        <td id=\"T_37f13_row13_col0\" class=\"data row13 col0\" >0.020000</td>\n",
       "                        <td id=\"T_37f13_row13_col1\" class=\"data row13 col1\" >0.020000</td>\n",
       "                        <td id=\"T_37f13_row13_col2\" class=\"data row13 col2\" >0.020000</td>\n",
       "                        <td id=\"T_37f13_row13_col3\" class=\"data row13 col3\" >0.020000</td>\n",
       "                        <td id=\"T_37f13_row13_col4\" class=\"data row13 col4\" >0.940000</td>\n",
       "                        <td id=\"T_37f13_row13_col5\" class=\"data row13 col5\" >4</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_37f13_level0_row14\" class=\"row_heading level0 row14\" >Doc14</th>\n",
       "                        <td id=\"T_37f13_row14_col0\" class=\"data row14 col0\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row14_col1\" class=\"data row14 col1\" >0.970000</td>\n",
       "                        <td id=\"T_37f13_row14_col2\" class=\"data row14 col2\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row14_col3\" class=\"data row14 col3\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row14_col4\" class=\"data row14 col4\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row14_col5\" class=\"data row14 col5\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_37f13_level0_row15\" class=\"row_heading level0 row15\" >Doc15</th>\n",
       "                        <td id=\"T_37f13_row15_col0\" class=\"data row15 col0\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row15_col1\" class=\"data row15 col1\" >0.970000</td>\n",
       "                        <td id=\"T_37f13_row15_col2\" class=\"data row15 col2\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row15_col3\" class=\"data row15 col3\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row15_col4\" class=\"data row15 col4\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row15_col5\" class=\"data row15 col5\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_37f13_level0_row16\" class=\"row_heading level0 row16\" >Doc16</th>\n",
       "                        <td id=\"T_37f13_row16_col0\" class=\"data row16 col0\" >0.190000</td>\n",
       "                        <td id=\"T_37f13_row16_col1\" class=\"data row16 col1\" >0.790000</td>\n",
       "                        <td id=\"T_37f13_row16_col2\" class=\"data row16 col2\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row16_col3\" class=\"data row16 col3\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row16_col4\" class=\"data row16 col4\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row16_col5\" class=\"data row16 col5\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_37f13_level0_row17\" class=\"row_heading level0 row17\" >Doc17</th>\n",
       "                        <td id=\"T_37f13_row17_col0\" class=\"data row17 col0\" >0.020000</td>\n",
       "                        <td id=\"T_37f13_row17_col1\" class=\"data row17 col1\" >0.020000</td>\n",
       "                        <td id=\"T_37f13_row17_col2\" class=\"data row17 col2\" >0.020000</td>\n",
       "                        <td id=\"T_37f13_row17_col3\" class=\"data row17 col3\" >0.910000</td>\n",
       "                        <td id=\"T_37f13_row17_col4\" class=\"data row17 col4\" >0.020000</td>\n",
       "                        <td id=\"T_37f13_row17_col5\" class=\"data row17 col5\" >3</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_37f13_level0_row18\" class=\"row_heading level0 row18\" >Doc18</th>\n",
       "                        <td id=\"T_37f13_row18_col0\" class=\"data row18 col0\" >0.040000</td>\n",
       "                        <td id=\"T_37f13_row18_col1\" class=\"data row18 col1\" >0.840000</td>\n",
       "                        <td id=\"T_37f13_row18_col2\" class=\"data row18 col2\" >0.040000</td>\n",
       "                        <td id=\"T_37f13_row18_col3\" class=\"data row18 col3\" >0.040000</td>\n",
       "                        <td id=\"T_37f13_row18_col4\" class=\"data row18 col4\" >0.040000</td>\n",
       "                        <td id=\"T_37f13_row18_col5\" class=\"data row18 col5\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_37f13_level0_row19\" class=\"row_heading level0 row19\" >Doc19</th>\n",
       "                        <td id=\"T_37f13_row19_col0\" class=\"data row19 col0\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row19_col1\" class=\"data row19 col1\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row19_col2\" class=\"data row19 col2\" >0.970000</td>\n",
       "                        <td id=\"T_37f13_row19_col3\" class=\"data row19 col3\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row19_col4\" class=\"data row19 col4\" >0.010000</td>\n",
       "                        <td id=\"T_37f13_row19_col5\" class=\"data row19 col5\" >2</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe517616a30>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Document - Topic Matrix\n",
    "lda_output = best_lda_model.transform(data_vectorized)\n",
    "\n",
    "# column names\n",
    "topicnames = [\"Topic\" + str(i) for i in range(best_lda_model.n_components)]\n",
    "\n",
    "# index names\n",
    "docnames = [\"Doc\" + str(i) for i in range(len(data))]\n",
    "\n",
    "# Make the pandas dataframe\n",
    "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topicnames, index=docnames)\n",
    "\n",
    "# Get dominant topic for each document\n",
    "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
    "df_document_topic['dominant_topic'] = dominant_topic\n",
    "\n",
    "# Styling\n",
    "def color_green(val):\n",
    "    color = 'green' if val > .1 else 'black'\n",
    "    return 'color: {col}'.format(col=color)\n",
    "\n",
    "def make_bold(val):\n",
    "    weight = 700 if val > .1 else 400\n",
    "    return 'font-weight: {weight}'.format(weight=weight)\n",
    "\n",
    "# Apply Style\n",
    "df_document_topics = df_document_topic.head(20).style.applymap(color_green).applymap(make_bold)\n",
    "df_document_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "27781676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accent</th>\n",
       "      <th>accentuate</th>\n",
       "      <th>accord</th>\n",
       "      <th>actual</th>\n",
       "      <th>actually</th>\n",
       "      <th>add</th>\n",
       "      <th>addition</th>\n",
       "      <th>adorable</th>\n",
       "      <th>...</th>\n",
       "      <th>wrinkle</th>\n",
       "      <th>wrong</th>\n",
       "      <th>xl</th>\n",
       "      <th>xs</th>\n",
       "      <th>xsp</th>\n",
       "      <th>xxs</th>\n",
       "      <th>year</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>zipper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic0</th>\n",
       "      <td>0.201366</td>\n",
       "      <td>0.200936</td>\n",
       "      <td>1.200155</td>\n",
       "      <td>0.201774</td>\n",
       "      <td>0.200002</td>\n",
       "      <td>0.200004</td>\n",
       "      <td>3.345366</td>\n",
       "      <td>3.922854</td>\n",
       "      <td>0.200005</td>\n",
       "      <td>0.202277</td>\n",
       "      <td>...</td>\n",
       "      <td>1.198189</td>\n",
       "      <td>2.199563</td>\n",
       "      <td>0.200002</td>\n",
       "      <td>9.832435</td>\n",
       "      <td>0.202477</td>\n",
       "      <td>2.871610</td>\n",
       "      <td>0.200004</td>\n",
       "      <td>0.227159</td>\n",
       "      <td>3.195828</td>\n",
       "      <td>0.200003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic1</th>\n",
       "      <td>0.200006</td>\n",
       "      <td>0.645189</td>\n",
       "      <td>1.196477</td>\n",
       "      <td>0.200004</td>\n",
       "      <td>0.200002</td>\n",
       "      <td>0.201397</td>\n",
       "      <td>2.306366</td>\n",
       "      <td>0.200271</td>\n",
       "      <td>0.200005</td>\n",
       "      <td>1.313182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200012</td>\n",
       "      <td>0.200007</td>\n",
       "      <td>2.198880</td>\n",
       "      <td>0.200822</td>\n",
       "      <td>0.200007</td>\n",
       "      <td>1.528829</td>\n",
       "      <td>2.194552</td>\n",
       "      <td>1.200424</td>\n",
       "      <td>0.200002</td>\n",
       "      <td>2.199989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic2</th>\n",
       "      <td>5.198896</td>\n",
       "      <td>7.612091</td>\n",
       "      <td>0.200001</td>\n",
       "      <td>3.198077</td>\n",
       "      <td>0.200125</td>\n",
       "      <td>1.199839</td>\n",
       "      <td>7.771598</td>\n",
       "      <td>4.649641</td>\n",
       "      <td>1.407033</td>\n",
       "      <td>0.200606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202463</td>\n",
       "      <td>0.200003</td>\n",
       "      <td>0.200312</td>\n",
       "      <td>12.894674</td>\n",
       "      <td>0.200003</td>\n",
       "      <td>2.364690</td>\n",
       "      <td>0.202681</td>\n",
       "      <td>0.208176</td>\n",
       "      <td>0.201679</td>\n",
       "      <td>0.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic3</th>\n",
       "      <td>1.200095</td>\n",
       "      <td>1.337463</td>\n",
       "      <td>0.200003</td>\n",
       "      <td>1.200140</td>\n",
       "      <td>0.200002</td>\n",
       "      <td>0.200004</td>\n",
       "      <td>0.236645</td>\n",
       "      <td>3.197594</td>\n",
       "      <td>4.993275</td>\n",
       "      <td>3.182625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200011</td>\n",
       "      <td>1.199204</td>\n",
       "      <td>0.200002</td>\n",
       "      <td>0.737893</td>\n",
       "      <td>1.196902</td>\n",
       "      <td>0.200006</td>\n",
       "      <td>0.201599</td>\n",
       "      <td>0.200011</td>\n",
       "      <td>0.202488</td>\n",
       "      <td>0.200003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic4</th>\n",
       "      <td>1.199638</td>\n",
       "      <td>0.204322</td>\n",
       "      <td>0.203364</td>\n",
       "      <td>0.200004</td>\n",
       "      <td>3.199868</td>\n",
       "      <td>1.198757</td>\n",
       "      <td>2.340024</td>\n",
       "      <td>4.029639</td>\n",
       "      <td>1.199682</td>\n",
       "      <td>8.101310</td>\n",
       "      <td>...</td>\n",
       "      <td>1.199326</td>\n",
       "      <td>2.201223</td>\n",
       "      <td>0.200805</td>\n",
       "      <td>23.334175</td>\n",
       "      <td>1.200611</td>\n",
       "      <td>4.034866</td>\n",
       "      <td>4.201165</td>\n",
       "      <td>1.164230</td>\n",
       "      <td>0.200002</td>\n",
       "      <td>0.200003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 709 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            able  absolutely    accent  accentuate    accord    actual  \\\n",
       "Topic0  0.201366    0.200936  1.200155    0.201774  0.200002  0.200004   \n",
       "Topic1  0.200006    0.645189  1.196477    0.200004  0.200002  0.201397   \n",
       "Topic2  5.198896    7.612091  0.200001    3.198077  0.200125  1.199839   \n",
       "Topic3  1.200095    1.337463  0.200003    1.200140  0.200002  0.200004   \n",
       "Topic4  1.199638    0.204322  0.203364    0.200004  3.199868  1.198757   \n",
       "\n",
       "        actually       add  addition  adorable  ...   wrinkle     wrong  \\\n",
       "Topic0  3.345366  3.922854  0.200005  0.202277  ...  1.198189  2.199563   \n",
       "Topic1  2.306366  0.200271  0.200005  1.313182  ...  0.200012  0.200007   \n",
       "Topic2  7.771598  4.649641  1.407033  0.200606  ...  0.202463  0.200003   \n",
       "Topic3  0.236645  3.197594  4.993275  3.182625  ...  0.200011  1.199204   \n",
       "Topic4  2.340024  4.029639  1.199682  8.101310  ...  1.199326  2.201223   \n",
       "\n",
       "              xl         xs       xsp       xxs      year    yellow  \\\n",
       "Topic0  0.200002   9.832435  0.202477  2.871610  0.200004  0.227159   \n",
       "Topic1  2.198880   0.200822  0.200007  1.528829  2.194552  1.200424   \n",
       "Topic2  0.200312  12.894674  0.200003  2.364690  0.202681  0.208176   \n",
       "Topic3  0.200002   0.737893  1.196902  0.200006  0.201599  0.200011   \n",
       "Topic4  0.200805  23.334175  1.200611  4.034866  4.201165  1.164230   \n",
       "\n",
       "        yesterday    zipper  \n",
       "Topic0   3.195828  0.200003  \n",
       "Topic1   0.200002  2.199989  \n",
       "Topic2   0.201679  0.200001  \n",
       "Topic3   0.202488  0.200003  \n",
       "Topic4   0.200002  0.200003  \n",
       "\n",
       "[5 rows x 709 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Topic-Keyword Matrix\n",
    "df_topic_keywords = pd.DataFrame(best_lda_model.components_)\n",
    "\n",
    "# Assign Column and Index\n",
    "df_topic_keywords.columns = vectorizer.get_feature_names()\n",
    "df_topic_keywords.index = topicnames\n",
    "\n",
    "# View\n",
    "df_topic_keywords.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "4f4bd6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 0</th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Word 3</th>\n",
       "      <th>Word 4</th>\n",
       "      <th>Word 5</th>\n",
       "      <th>Word 6</th>\n",
       "      <th>Word 7</th>\n",
       "      <th>Word 8</th>\n",
       "      <th>Word 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic 0</th>\n",
       "      <td>size</td>\n",
       "      <td>small</td>\n",
       "      <td>fit</td>\n",
       "      <td>shirt</td>\n",
       "      <td>look</td>\n",
       "      <td>love</td>\n",
       "      <td>order</td>\n",
       "      <td>try</td>\n",
       "      <td>just</td>\n",
       "      <td>wide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 1</th>\n",
       "      <td>wear</td>\n",
       "      <td>look</td>\n",
       "      <td>color</td>\n",
       "      <td>love</td>\n",
       "      <td>long</td>\n",
       "      <td>comfortable</td>\n",
       "      <td>fabric</td>\n",
       "      <td>tunic</td>\n",
       "      <td>fit</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 2</th>\n",
       "      <td>size</td>\n",
       "      <td>look</td>\n",
       "      <td>wear</td>\n",
       "      <td>just</td>\n",
       "      <td>love</td>\n",
       "      <td>shirt</td>\n",
       "      <td>fit</td>\n",
       "      <td>color</td>\n",
       "      <td>fabric</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 3</th>\n",
       "      <td>wear</td>\n",
       "      <td>love</td>\n",
       "      <td>shirt</td>\n",
       "      <td>look</td>\n",
       "      <td>really</td>\n",
       "      <td>cute</td>\n",
       "      <td>material</td>\n",
       "      <td>fabric</td>\n",
       "      <td>nice</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 4</th>\n",
       "      <td>love</td>\n",
       "      <td>color</td>\n",
       "      <td>large</td>\n",
       "      <td>xs</td>\n",
       "      <td>wear</td>\n",
       "      <td>great</td>\n",
       "      <td>way</td>\n",
       "      <td>small</td>\n",
       "      <td>cute</td>\n",
       "      <td>look</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word 0 Word 1 Word 2 Word 3  Word 4       Word 5    Word 6  Word 7  \\\n",
       "Topic 0   size  small    fit  shirt    look         love     order     try   \n",
       "Topic 1   wear   look  color   love    long  comfortable    fabric   tunic   \n",
       "Topic 2   size   look   wear   just    love        shirt       fit   color   \n",
       "Topic 3   wear   love  shirt   look  really         cute  material  fabric   \n",
       "Topic 4   love  color  large     xs    wear        great       way   small   \n",
       "\n",
       "         Word 8 Word 9  \n",
       "Topic 0    just   wide  \n",
       "Topic 1     fit  great  \n",
       "Topic 2  fabric  large  \n",
       "Topic 3    nice  great  \n",
       "Topic 4    cute   look  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show top n keywords for each topic\n",
    "def show_topics(vectorizer=vectorizer, lda_model=lda_model, n_words=10):\n",
    "    keywords = np.array(vectorizer.get_feature_names())\n",
    "    topic_keywords = []\n",
    "    for topic_weights in lda_model.components_:\n",
    "        top_keyword_locs = (-topic_weights).argsort()[:n_words]\n",
    "        topic_keywords.append(keywords.take(top_keyword_locs))\n",
    "    return topic_keywords\n",
    "\n",
    "topic_keywords = show_topics(vectorizer=vectorizer, lda_model=best_lda_model, n_words=10)        \n",
    "\n",
    "# Topic - Keywords Dataframe\n",
    "df_topic_keywords = pd.DataFrame(topic_keywords)\n",
    "df_topic_keywords.columns = ['Word '+str(i) for i in range(df_topic_keywords.shape[1])]\n",
    "df_topic_keywords.index = ['Topic '+str(i) for i in range(df_topic_keywords.shape[0])]\n",
    "df_topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "710aaeda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el486651406216594172807927377096\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el486651406216594172807927377096_data = {\"mdsDat\": {\"x\": [150.22215270996094, 51.16336441040039, -73.1445541381836, -66.4101333618164, 54.41732406616211], \"y\": [-72.2695541381836, -159.968017578125, 21.523815155029297, -110.60643768310547, 12.44344425201416], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [37.58066589680991, 16.13522685846021, 15.626008320222429, 15.416619050440175, 15.241479874067274]}, \"tinfo\": {\"Term\": [\"size\", \"wear\", \"medium\", \"small\", \"large\", \"xs\", \"tunic\", \"comfortable\", \"wide\", \"try\", \"long\", \"length\", \"arm\", \"beautiful\", \"color\", \"perfect\", \"compliment\", \"tight\", \"jean\", \"really\", \"boxy\", \"sweater\", \"feel\", \"cute\", \"shirt\", \"way\", \"short\", \"sleeve\", \"fall\", \"love\", \"grey\", \"gorgeous\", \"moss\", \"second\", \"high\", \"feel\", \"plain\", \"errand\", \"chance\", \"generous\", \"blouse\", \"favorite\", \"skirt\", \"knit\", \"new\", \"fix\", \"keeper\", \"currently\", \"cross\", \"sexy\", \"available\", \"wonderfully\", \"classy\", \"change\", \"tailor\", \"subtle\", \"concerned\", \"waiste\", \"comfy\", \"absolutely\", \"shape\", \"tie\", \"medium\", \"happy\", \"woman\", \"dress\", \"just\", \"size\", \"flatter\", \"hope\", \"run\", \"feminine\", \"large\", \"reviewer\", \"casual\", \"work\", \"look\", \"think\", \"wear\", \"fit\", \"shirt\", \"color\", \"fabric\", \"little\", \"great\", \"make\", \"order\", \"love\", \"big\", \"true\", \"soft\", \"want\", \"small\", \"perfect\", \"buy\", \"bit\", \"super\", \"nice\", \"really\", \"good\", \"cute\", \"comfortable\", \"blah\", \"armpit\", \"yesterday\", \"thank\", \"issue\", \"tight\", \"instantly\", \"listen\", \"lose\", \"prevent\", \"truly\", \"attractive\", \"hopefully\", \"exchange\", \"modern\", \"boat\", \"midsection\", \"ridiculously\", \"pattern\", \"hold\", \"reference\", \"notice\", \"regular\", \"belt\", \"wide\", \"hole\", \"cool\", \"picture\", \"sell\", \"substantial\", \"sure\", \"arm\", \"boxy\", \"try\", \"cut\", \"length\", \"small\", \"short\", \"size\", \"sleeve\", \"line\", \"stretch\", \"want\", \"medium\", \"order\", \"fit\", \"shirt\", \"lbs\", \"just\", \"return\", \"love\", \"look\", \"really\", \"long\", \"large\", \"run\", \"cute\", \"way\", \"think\", \"buy\", \"weekend\", \"lie\", \"trend\", \"bum\", \"plenty\", \"compliment\", \"denim\", \"minute\", \"dressing\", \"happen\", \"unexpected\", \"bralette\", \"postpartum\", \"turquoise\", \"statement\", \"lint\", \"dislike\", \"washer\", \"doll\", \"detailing\", \"wine\", \"shopping\", \"thrill\", \"miss\", \"thread\", \"vibrant\", \"time\", \"texture\", \"flat\", \"med\", \"receive\", \"addition\", \"cheap\", \"stripe\", \"blend\", \"nice\", \"really\", \"white\", \"people\", \"appear\", \"clingy\", \"middle\", \"rib\", \"material\", \"cute\", \"tummy\", \"wear\", \"shirt\", \"use\", \"blue\", \"love\", \"ve\", \"lot\", \"tank\", \"look\", \"price\", \"quality\", \"fabric\", \"like\", \"great\", \"return\", \"buy\", \"perfect\", \"make\", \"jean\", \"soft\", \"little\", \"fit\", \"bit\", \"color\", \"comfortable\", \"small\", \"winter\", \"tunic\", \"versatile\", \"ton\", \"spring\", \"neutral\", \"combination\", \"raw\", \"transition\", \"tan\", \"zipper\", \"flaw\", \"movement\", \"justice\", \"xl\", \"unfinished\", \"jegging\", \"follow\", \"armhole\", \"chic\", \"slit\", \"deliver\", \"holiday\", \"decent\", \"forward\", \"event\", \"crop\", \"pic\", \"edge\", \"sweater\", \"light\", \"fall\", \"long\", \"comfortable\", \"red\", \"warm\", \"summer\", \"legging\", \"jean\", \"stretch\", \"wear\", \"color\", \"beautiful\", \"perfect\", \"look\", \"tall\", \"wash\", \"piece\", \"love\", \"wish\", \"fabric\", \"great\", \"soft\", \"fit\", \"make\", \"dress\", \"model\", \"good\", \"length\", \"flattering\", \"short\", \"shirt\", \"little\", \"material\", \"size\", \"cute\", \"tone\", \"hard\", \"finally\", \"accord\", \"literally\", \"inch\", \"girl\", \"flow\", \"couple\", \"visual\", \"rest\", \"clothe\", \"teal\", \"laugh\", \"gal\", \"apparent\", \"deep\", \"nearly\", \"attention\", \"totally\", \"softness\", \"wedge\", \"rich\", \"bust\", \"daughter\", \"classic\", \"rise\", \"basic\", \"adorable\", \"year\", \"xs\", \"pink\", \"retailer\", \"way\", \"shoulder\", \"pretty\", \"low\", \"purchase\", \"beautiful\", \"large\", \"strap\", \"week\", \"half\", \"tall\", \"online\", \"color\", \"great\", \"love\", \"cute\", \"buy\", \"small\", \"soft\", \"order\", \"normally\", \"fabric\", \"wear\", \"really\", \"look\", \"shirt\", \"fit\", \"tee\", \"style\", \"size\", \"good\", \"just\", \"material\"], \"Freq\": [151.0, 182.0, 60.0, 107.0, 84.0, 43.0, 21.0, 54.0, 34.0, 45.0, 55.0, 39.0, 40.0, 33.0, 126.0, 54.0, 17.0, 20.0, 45.0, 90.0, 29.0, 20.0, 45.0, 91.0, 149.0, 47.0, 46.0, 51.0, 31.0, 177.0, 6.782674855689569, 4.908858893926766, 4.907794268313315, 4.905364867644566, 15.484706341217578, 38.061213038223116, 3.9630088937668932, 3.961645890854709, 3.9615267585263516, 3.9597621245140595, 13.313315151934633, 7.741116241456211, 12.362656516873937, 7.70407615173035, 6.796522260851507, 3.020204760691628, 3.020062853720577, 3.0194585694827643, 3.019454388174578, 3.0189218225774126, 3.0178737687303476, 3.0176760331918855, 3.0171328087883063, 3.0163694285205036, 3.0153155667301537, 3.013074877839238, 3.011179811399916, 3.010328094890437, 20.15274906776278, 7.185921411196994, 12.162324695361828, 15.292734129795223, 41.25403134616324, 7.5977936389090655, 5.642943856403581, 23.210299886539218, 62.56737990726437, 82.37297126052836, 11.49515357189191, 12.043739725025187, 34.14641595975577, 4.910184771144644, 44.663630220376255, 12.64474316505752, 15.038744816933924, 26.737912574569425, 79.93143861591997, 23.66110448200078, 75.35505869491489, 60.04074486130131, 61.77958798602773, 54.030032188585615, 48.725166784845364, 26.300571738311557, 43.97810158288892, 33.184097109477726, 38.46369167924523, 62.30297980413028, 23.790152963165717, 16.52527038750009, 31.929667524137184, 18.823888426062396, 37.373347866407734, 24.298748050192085, 28.79339497137248, 20.02775089885986, 19.315674915550336, 21.710506369981367, 26.22979527442907, 20.871691078008258, 24.919525732450715, 20.15421730841917, 2.938056807379754, 2.935351496416406, 2.934230548599503, 2.933896018347344, 6.366425285197164, 15.04331897353247, 2.0199113828478636, 2.0199077843181112, 2.0195270926426847, 2.019352335002487, 2.019117287085786, 2.018510655585219, 2.0178886610819657, 2.0173356312251376, 2.0170413968859053, 2.0096629071813887, 2.00867304415318, 1.9840563343854627, 3.8177466995562788, 5.017656774528532, 9.892610343510828, 2.9290238451570043, 6.344510381431751, 2.832910304071533, 21.054402741035737, 7.2209896613085585, 3.855978047916286, 12.32672161042857, 5.286896879959482, 2.0171515588102262, 9.61465506166773, 20.415900511106692, 15.198300110451955, 21.722296224417786, 15.032994082430493, 18.74812608283667, 38.65989196007798, 19.721176977667263, 47.56454997132472, 20.34313028283577, 6.107007813518298, 6.605354581347184, 12.52552948750253, 18.623856064579154, 24.301101289366212, 32.38140473104092, 28.557656790697646, 11.587925521367483, 21.50294068048498, 11.167969968367418, 24.74570569938202, 25.428101527128064, 16.76694165712179, 12.781236573742213, 15.189899036216355, 12.56233270108829, 14.339463682711793, 10.691378112021512, 10.047429581619419, 9.912113891522026, 4.6987702317973294, 3.7738400743621687, 2.8926842791316987, 2.8923339859001045, 2.889022328145835, 13.572648087402216, 4.70142607975396, 1.988950592398498, 1.9889501516763273, 1.988949724404351, 1.9889495191724682, 1.9889494613838699, 1.9889486587739817, 1.988947931400804, 1.9889474733632302, 1.9888127559377924, 1.9884283880107818, 1.9880145427919957, 1.9876332918537098, 1.9870217463691446, 1.9831437493829462, 1.981346773956819, 1.9798966505367326, 1.9761019832688684, 1.9719828825352674, 1.9707056068397908, 11.660192058096001, 6.315251168074018, 3.7807976248660284, 4.69809403219225, 11.60209195958104, 4.514268849563557, 5.420160457403638, 8.203836820780367, 3.799321630085368, 18.23550652232821, 26.88949703316582, 15.017421551754161, 4.4979937686486595, 4.841289443434813, 2.8975270177694337, 2.891821370423118, 2.891279708047945, 19.247535450340138, 25.010564193104106, 2.8942124842656267, 39.44349229340008, 33.82523629406988, 3.6565095924659703, 8.867681003865343, 35.466268712683224, 6.6968544868067434, 9.425084502738654, 8.404456849553801, 31.691426112655584, 6.029254374503209, 10.744799992585078, 18.478587963922468, 9.969564216130795, 16.739585934779377, 9.758245785771024, 13.89665902993126, 11.53781617093352, 12.954594480687277, 10.161950427561706, 11.977432497890721, 9.810564548952453, 13.62121918662966, 8.96464740101031, 11.350827830358723, 9.305716796003145, 9.495611187115275, 5.639726754660021, 19.006033864009854, 9.21640809615953, 3.8171671750646943, 7.279509604187384, 6.552473348579385, 2.867806602422385, 4.731149589142186, 4.706300780277595, 2.0015972335061183, 2.0015928534725864, 2.000867296975065, 2.000726971370187, 2.0007217527065904, 2.000583362155136, 2.0002347108097824, 2.000022394085194, 1.9990791563773374, 1.9983398650656894, 1.997889641964696, 1.9973556188584562, 1.994689756385862, 1.9924018324469472, 1.9854754081163706, 3.8244649871685557, 1.8675087208516898, 2.9101665652565747, 6.538109687998455, 5.309498192131019, 11.613683331222653, 12.220781326494935, 15.310698328811979, 23.264435795797155, 22.15685556838287, 8.572138280829684, 5.427487888172424, 10.221952088350934, 8.097873797163555, 16.013023998241607, 6.547607266807147, 42.17896955092823, 31.26287361271301, 12.012765068189932, 16.53644940569992, 39.167861381435046, 6.167631735766386, 9.46766027523709, 7.130384412972358, 28.685722481995107, 7.354581321792467, 19.590783050777524, 17.816162531539124, 13.869348103734689, 18.122885778406854, 13.220674034315135, 9.748688489772332, 8.840587445006117, 9.45931923562773, 8.8467157746639, 8.361608567077793, 8.796617301966396, 10.33713867296116, 8.790128612492316, 8.868375665557313, 9.084294008855176, 8.884950120320477, 5.657267141900821, 4.743280748560065, 3.8343490967663585, 2.922465939423749, 2.9222144507410506, 2.9222141966130026, 6.442254286501795, 8.33893399500681, 4.7506368574636975, 2.0092751383099374, 2.0092747547384393, 2.0092744956475688, 2.009273515452901, 2.0092718655376864, 2.0083224192567557, 2.0077523233871495, 2.0073067867791026, 2.007208581807793, 2.0052749345854015, 2.0005971394322586, 1.9858915703325488, 1.9367388262573, 1.9280931601658258, 9.00722863217734, 3.6267942952770027, 2.9207312576628928, 2.9240497644046624, 4.661025661591915, 7.398992732299604, 3.836957927462639, 21.311293021055352, 6.906139877768132, 12.64464156817187, 18.285424083275746, 13.223796458405161, 15.354656944108036, 7.71912275376016, 15.596768144496375, 12.085692015017283, 22.82926197615738, 3.686164129293044, 3.6773803993740666, 3.632624585976164, 5.855424730932772, 9.107033181941068, 23.011064351791802, 19.391626469158467, 26.752245531764828, 17.859441741850652, 15.618500953229344, 18.08968631206469, 14.548382847146156, 15.700127989240631, 8.003476624752869, 16.131722392702965, 20.255673944148082, 13.182689269143783, 16.922399381580792, 15.230930211355961, 14.74478249365113, 9.056010498898335, 9.07833570311639, 12.558704176492391, 9.56105242933638, 11.300969570016308, 10.010702574993495], \"Total\": [151.0, 182.0, 60.0, 107.0, 84.0, 43.0, 21.0, 54.0, 34.0, 45.0, 55.0, 39.0, 40.0, 33.0, 126.0, 54.0, 17.0, 20.0, 45.0, 90.0, 29.0, 20.0, 45.0, 91.0, 149.0, 47.0, 46.0, 51.0, 31.0, 177.0, 7.525576620460002, 5.637940928158724, 5.6379117712017, 5.637812862229646, 17.846674515879283, 45.06290476629048, 4.693849200945131, 4.693809876966262, 4.693810972330504, 4.693746902731106, 15.950391691748203, 9.374069775135142, 15.004242163812913, 9.373046413880465, 8.430026113357629, 3.7498901169417302, 3.749880316316028, 3.74986308300746, 3.7498629381043287, 3.74984364890471, 3.7497914932677197, 3.7497839308814145, 3.7498114207181446, 3.7497905247731986, 3.749726319302361, 3.749683399830945, 3.7495910928755096, 3.7494761305860056, 25.307999552894792, 9.35318252511053, 15.916397734163807, 20.57654222489968, 60.801812517118734, 10.273450302176082, 7.484194682431375, 36.31256762227755, 110.7179313778697, 151.7624042769788, 16.831153034524018, 17.754185835959497, 59.59771985956689, 6.551292184177871, 84.62514508789951, 19.59913347391623, 24.154648246911364, 48.32582909853234, 193.14122701871946, 42.81073054192535, 182.75034740583806, 138.9110370510299, 149.73054995511237, 126.68179291172693, 111.87837123075032, 50.978109560674945, 100.75660146209279, 70.34039260859538, 89.87830084547906, 177.95292222995545, 47.28035497129987, 27.939831537476543, 73.01799424394578, 34.463893393569734, 107.25204559816308, 54.50074997586126, 76.61913631484353, 39.82591010803348, 37.99787795506086, 51.682730401549264, 90.14378254050295, 48.12488397155078, 91.01394547043776, 54.36166207973033, 3.672303262153586, 3.6723500744781132, 3.672311662020073, 3.6722450316594664, 8.245289469148027, 20.247354609552378, 2.7541591909877283, 2.7541591739832323, 2.7541700482910496, 2.7541749712469663, 2.7541814405948597, 2.7541518135012204, 2.754128178630162, 2.7541490778241124, 2.754142168452042, 2.7542101138750996, 2.754289112784366, 2.7538933038864704, 5.53548052523843, 7.320631734447322, 15.582012467721828, 4.616191970678463, 10.120487687700994, 4.579348175420819, 34.057734342592674, 11.961750703277739, 6.410109064724465, 21.11951781045744, 9.16003304232647, 3.658268835501896, 17.453678845194815, 40.64085215616699, 29.5323953103783, 45.088306294489314, 30.361382898676233, 39.65586810987882, 107.25204559816308, 46.99365151583163, 151.7624042769788, 51.45222133732822, 11.887878989734492, 13.713749124794527, 34.463893393569734, 60.801812517118734, 89.87830084547906, 138.9110370510299, 149.73054995511237, 37.056475795306376, 110.7179313778697, 36.7824221352139, 177.95292222995545, 193.14122701871946, 90.14378254050295, 55.92982561977189, 84.62514508789951, 59.59771985956689, 91.01394547043776, 47.769624489732635, 42.81073054192535, 76.61913631484353, 5.4383024598352945, 4.534397695408603, 3.630083758564249, 3.630110532558843, 3.630128659527368, 17.211089397186647, 6.382183484535606, 2.726010588074548, 2.726010594026846, 2.726010600617587, 2.7260106030152937, 2.7260106047328625, 2.7260106159564175, 2.726010626803464, 2.726010634216615, 2.7260166657976113, 2.7260139634705163, 2.726051912611207, 2.7260485350664885, 2.7260303301022732, 2.7261212450670875, 2.726346002664831, 2.726228365938083, 2.726577894262562, 2.7262046253040326, 2.726126695822055, 16.328329417593103, 9.103365376449126, 5.478157624932986, 7.274547094763314, 21.873608845631193, 7.303808911923296, 9.182502107036166, 15.47010559383596, 6.396167548846509, 51.682730401549264, 90.14378254050295, 42.37402761263012, 8.221286816951435, 9.095725689869445, 4.5487112324097785, 4.539921278981498, 4.54339882815647, 62.47519713959145, 91.01394547043776, 4.5740413232795385, 182.75034740583806, 149.73054995511237, 6.428258871373591, 22.79274857455801, 177.95292222995545, 15.594835063620456, 25.828669738305706, 22.097669389632237, 193.14122701871946, 13.7469481189985, 40.57539407662162, 111.87837123075032, 36.937218798234596, 100.75660146209279, 36.7824221352139, 76.61913631484353, 54.50074997586126, 70.34039260859538, 45.95252282692674, 73.01799424394578, 50.978109560674945, 138.9110370510299, 39.82591010803348, 126.68179291172693, 54.36166207973033, 107.25204559816308, 6.376787791593114, 21.86974015726791, 10.931169353676967, 4.55717464112121, 9.110487516410076, 8.230442540079132, 3.647477823614002, 6.380238518945573, 6.381231823054119, 2.73750998898583, 2.737510019637926, 2.737512787435561, 2.737504465204685, 2.7375044950393774, 2.7375234269426056, 2.7375612025805225, 2.7375689632244207, 2.7375196418767525, 2.737594002511701, 2.7374960668348822, 2.7376535186859074, 2.737769382467563, 2.737855064569111, 2.7376459982207377, 5.50104113697825, 2.7425492893650736, 4.551407059554191, 11.029162157824889, 9.087327786224769, 20.060574659824944, 22.92398856768156, 31.952622617253176, 55.92982561977189, 54.36166207973033, 17.397071120091887, 10.012612928503613, 22.922457256171203, 17.49276404209255, 45.95252282692674, 13.713749124794527, 182.75034740583806, 126.68179291172693, 33.073420215694526, 54.50074997586126, 193.14122701871946, 13.687134706383226, 25.663341179576022, 17.416423298358715, 177.95292222995545, 18.424784575180013, 111.87837123075032, 100.75660146209279, 73.01799424394578, 138.9110370510299, 70.34039260859538, 36.31256762227755, 33.3799520373326, 48.12488397155078, 39.65586810987882, 35.017569402811375, 46.99365151583163, 149.73054995511237, 50.978109560674945, 62.47519713959145, 151.7624042769788, 91.01394547043776, 6.397815019090155, 5.48446135002466, 4.571116809384506, 3.6577994144862247, 3.657791890602243, 3.657791890554063, 8.259299193665965, 10.974264424116983, 6.3942492164330496, 2.7444874341064236, 2.744487434936063, 2.744487436202304, 2.7444874375641453, 2.7444874402896917, 2.744492474259684, 2.7445385429347073, 2.744467569673429, 2.7445365003500877, 2.7445085970105874, 2.7447775977968987, 2.7444516896013083, 2.7442638608364347, 2.744177362155861, 12.893279010965848, 5.47315076846246, 4.561882957575827, 4.6017132359714354, 7.335501590205377, 11.846160318144971, 6.390829191758762, 43.3614575009087, 12.871452649618114, 28.48756987970945, 47.769624489732635, 32.276302677091365, 39.88016763345185, 16.502832655414437, 45.18961669219168, 33.073420215694526, 84.62514508789951, 6.464096177202842, 6.464460675717032, 6.416995577054454, 13.687134706383226, 26.744356897827664, 126.68179291172693, 100.75660146209279, 177.95292222995545, 91.01394547043776, 76.61913631484353, 107.25204559816308, 73.01799424394578, 89.87830084547906, 26.71487262536705, 111.87837123075032, 182.75034740583806, 90.14378254050295, 193.14122701871946, 149.73054995511237, 138.9110370510299, 37.71036255935387, 38.68988397138633, 151.7624042769788, 48.12488397155078, 110.7179313778697, 62.47519713959145], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.1597, -6.483, -6.4832, -6.4837, -5.3342, -4.4349, -6.6971, -6.6974, -6.6974, -6.6979, -5.4853, -6.0275, -5.5594, -6.0323, -6.1577, -6.9687, -6.9688, -6.969, -6.969, -6.9692, -6.9695, -6.9696, -6.9698, -6.97, -6.9704, -6.9711, -6.9717, -6.972, -5.0707, -6.1019, -5.5757, -5.3467, -4.3543, -6.0462, -6.3437, -4.9295, -3.9378, -3.6628, -5.6321, -5.5855, -4.5434, -6.4828, -4.2749, -5.5368, -5.3634, -4.788, -3.6929, -4.9102, -3.7519, -3.979, -3.9505, -4.0845, -4.1879, -4.8045, -4.2904, -4.572, -4.4244, -3.9421, -4.9048, -5.2692, -4.6105, -5.1389, -4.4531, -4.8836, -4.7139, -5.077, -5.1132, -4.9963, -4.8072, -5.0357, -4.8584, -5.0707, -6.1508, -6.1518, -6.1521, -6.1523, -5.3775, -4.5177, -6.5255, -6.5255, -6.5257, -6.5258, -6.5259, -6.5262, -6.5265, -6.5268, -6.527, -6.5306, -6.5311, -6.5434, -5.8889, -5.6156, -4.9368, -6.1539, -5.381, -6.1873, -4.1815, -5.2516, -5.879, -4.7168, -5.5634, -6.5269, -4.9653, -4.2123, -4.5074, -4.1502, -4.5183, -4.2975, -3.5738, -4.2469, -3.3665, -4.2158, -5.4191, -5.3407, -4.7008, -4.3041, -4.0381, -3.751, -3.8767, -4.7786, -4.1604, -4.8155, -4.0199, -3.9927, -4.4092, -4.6806, -4.508, -4.6979, -4.5656, -4.8591, -4.9213, -4.9348, -5.6492, -5.8684, -6.1343, -6.1345, -6.1356, -4.5885, -5.6487, -6.5089, -6.5089, -6.5089, -6.5089, -6.5089, -6.5089, -6.5089, -6.5089, -6.509, -6.5092, -6.5094, -6.5096, -6.5099, -6.5118, -6.5127, -6.5135, -6.5154, -6.5175, -6.5181, -4.7403, -5.3535, -5.8666, -5.6494, -4.7453, -5.6893, -5.5064, -5.0919, -5.8617, -4.2931, -3.9048, -4.4873, -5.6929, -5.6193, -6.1327, -6.1346, -6.1348, -4.2391, -3.9772, -6.1338, -3.5216, -3.6753, -5.9, -5.0141, -3.6279, -5.2949, -4.9531, -5.0678, -3.7405, -5.3999, -4.8221, -4.2799, -4.897, -4.3787, -4.9184, -4.5649, -4.7509, -4.6351, -4.8779, -4.7135, -4.9131, -4.5849, -5.0032, -4.7672, -4.9659, -4.9457, -5.4532, -4.2383, -4.962, -5.8435, -5.198, -5.3032, -6.1295, -5.6289, -5.6341, -6.4891, -6.4891, -6.4894, -6.4895, -6.4895, -6.4896, -6.4898, -6.4899, -6.4903, -6.4907, -6.4909, -6.4912, -6.4925, -6.4937, -6.4972, -5.8416, -6.5584, -6.1148, -5.3054, -5.5135, -4.7308, -4.6799, -4.4545, -4.0361, -4.0849, -5.0345, -5.4915, -4.8585, -5.0914, -4.4096, -5.3039, -3.4411, -3.7406, -4.6971, -4.3775, -3.5152, -5.3637, -4.9351, -5.2187, -3.8266, -5.1877, -4.208, -4.3029, -4.5533, -4.2859, -4.6012, -4.9059, -5.0037, -4.936, -5.003, -5.0594, -5.0087, -4.8473, -5.0094, -5.0005, -4.9765, -4.9987, -5.4387, -5.6149, -5.8276, -6.0992, -6.0993, -6.0993, -5.3087, -5.0507, -5.6133, -6.4738, -6.4738, -6.4738, -6.4738, -6.4738, -6.4743, -6.4746, -6.4748, -6.4749, -6.4758, -6.4782, -6.4855, -6.5106, -6.5151, -4.9736, -5.8833, -6.0998, -6.0986, -5.6324, -5.1703, -5.8269, -4.1124, -5.2392, -4.6344, -4.2655, -4.5896, -4.4402, -5.1279, -4.4245, -4.6796, -4.0436, -5.867, -5.8694, -5.8816, -5.4042, -4.9626, -4.0356, -4.2068, -3.885, -4.2891, -4.4231, -4.2763, -4.4941, -4.4179, -5.0917, -4.3908, -4.1632, -4.5927, -4.343, -4.4483, -4.4807, -4.9682, -4.9657, -4.6412, -4.9139, -4.7467, -4.8679], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.8747, 0.8402, 0.84, 0.8395, 0.8367, 0.8098, 0.8094, 0.8091, 0.8091, 0.8086, 0.798, 0.7873, 0.785, 0.7826, 0.7633, 0.7623, 0.7622, 0.762, 0.762, 0.7619, 0.7615, 0.7615, 0.7613, 0.761, 0.7607, 0.76, 0.7594, 0.7591, 0.7509, 0.7151, 0.7097, 0.6819, 0.5908, 0.677, 0.6963, 0.5311, 0.4079, 0.3676, 0.5974, 0.5906, 0.4217, 0.6903, 0.3396, 0.5404, 0.5048, 0.3868, 0.0964, 0.3857, 0.0928, 0.1399, 0.0934, 0.1265, 0.1475, 0.3169, 0.1497, 0.2274, 0.1299, -0.0708, 0.2919, 0.4535, 0.1515, 0.3739, -0.0755, 0.1709, -0.0, 0.2913, 0.3021, 0.1114, -0.2558, 0.1433, -0.3167, -0.0136, 1.6011, 1.6002, 1.5998, 1.5997, 1.5656, 1.5271, 1.5141, 1.5141, 1.5139, 1.5138, 1.5137, 1.5134, 1.5131, 1.5128, 1.5127, 1.509, 1.5085, 1.4963, 1.4526, 1.4464, 1.3698, 1.3693, 1.3572, 1.3439, 1.3432, 1.3194, 1.3159, 1.2857, 1.2745, 1.2289, 1.2279, 1.1357, 1.1599, 1.0939, 1.1212, 1.075, 0.8038, 0.9558, 0.6639, 0.8963, 1.1581, 1.0936, 0.812, 0.641, 0.5162, 0.3679, 0.1673, 0.6617, 0.1854, 0.6322, -0.1487, -0.2034, 0.1422, 0.348, 0.1066, 0.2673, -0.0238, 0.3272, 0.3747, -0.2209, 1.7101, 1.6726, 1.6292, 1.629, 1.6279, 1.6187, 1.5506, 1.541, 1.541, 1.541, 1.541, 1.541, 1.541, 1.541, 1.541, 1.5409, 1.5407, 1.5405, 1.5403, 1.54, 1.538, 1.537, 1.5364, 1.5343, 1.5324, 1.5317, 1.5195, 1.4906, 1.4854, 1.419, 1.2221, 1.3751, 1.3291, 1.2219, 1.3354, 0.8145, 0.6466, 0.8189, 1.2531, 1.2256, 1.4052, 1.4052, 1.4043, 0.6788, 0.5645, 1.3985, 0.323, 0.3686, 1.292, 0.9122, 0.2433, 1.0109, 0.8481, 0.8895, 0.0489, 1.032, 0.5275, 0.0554, 0.5466, 0.0613, 0.5293, 0.149, 0.3036, 0.1643, 0.3473, 0.0486, 0.2083, -0.466, 0.365, -0.5562, 0.0912, -0.5681, 1.7469, 1.7294, 1.6991, 1.6925, 1.6454, 1.6417, 1.6292, 1.5707, 1.5653, 1.5566, 1.5566, 1.5563, 1.5562, 1.5562, 1.5561, 1.5559, 1.5558, 1.5554, 1.555, 1.5548, 1.5544, 1.5531, 1.5519, 1.5485, 1.5062, 1.4854, 1.4225, 1.3468, 1.3323, 1.3232, 1.2407, 1.134, 0.9926, 0.9722, 1.1619, 1.2574, 1.0621, 1.0995, 0.8155, 1.1304, 0.4035, 0.4705, 0.857, 0.6771, 0.2742, 1.0726, 0.8725, 0.9767, 0.0446, 0.9514, 0.1274, 0.1371, 0.2087, -0.1669, 0.1982, 0.5547, 0.5411, 0.2429, 0.3695, 0.4375, 0.1941, -0.8034, 0.112, -0.0826, -0.946, -0.4569, 1.7581, 1.736, 1.7054, 1.6567, 1.6566, 1.6566, 1.6327, 1.6065, 1.584, 1.5693, 1.5693, 1.5693, 1.5693, 1.5693, 1.5689, 1.5686, 1.5684, 1.5683, 1.5673, 1.5649, 1.5576, 1.5326, 1.5282, 1.5225, 1.4696, 1.4352, 1.4277, 1.4277, 1.4105, 1.371, 1.1708, 1.2585, 1.0689, 0.9209, 0.9888, 0.9267, 1.1213, 0.8173, 0.8744, 0.571, 1.3195, 1.317, 1.3122, 1.0321, 0.8039, 0.1754, 0.2333, -0.0138, 0.2527, 0.2908, 0.1013, 0.2679, 0.1364, 0.6758, -0.0555, -0.3185, -0.0414, -0.5536, -0.4044, -0.3618, 0.4546, 0.4315, -0.6108, 0.265, -0.4009, 0.05]}, \"token.table\": {\"Topic\": [1, 3, 4, 5, 1, 3, 5, 3, 4, 5, 5, 2, 3, 5, 1, 2, 3, 5, 4, 2, 5, 2, 1, 1, 3, 5, 1, 3, 4, 5, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 2, 1, 2, 3, 1, 4, 1, 3, 4, 5, 2, 1, 2, 4, 5, 3, 3, 1, 5, 1, 2, 3, 4, 5, 1, 3, 4, 1, 1, 1, 3, 4, 3, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 4, 1, 3, 4, 5, 1, 4, 5, 3, 4, 1, 2, 4, 4, 5, 3, 4, 1, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 5, 4, 5, 4, 1, 3, 3, 3, 3, 1, 2, 3, 4, 3, 3, 4, 1, 4, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 1, 2, 4, 1, 5, 5, 1, 2, 3, 4, 5, 1, 1, 3, 1, 2, 5, 1, 2, 3, 4, 5, 4, 2, 5, 4, 1, 4, 5, 1, 1, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 1, 3, 5, 3, 1, 3, 5, 1, 2, 3, 2, 3, 1, 2, 3, 4, 1, 2, 3, 2, 5, 2, 2, 3, 1, 3, 4, 5, 4, 1, 2, 3, 4, 5, 4, 1, 1, 3, 1, 2, 3, 5, 5, 1, 2, 4, 5, 1, 3, 4, 1, 2, 4, 5, 3, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 4, 5, 3, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 3, 4, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 1, 2, 3, 4, 2, 3, 3, 1, 2, 3, 4, 5, 2, 1, 4, 5, 1, 4, 1, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 1, 3, 4, 1, 2, 3, 4, 5, 1, 4, 5, 1, 2, 4, 5, 1, 2, 3, 4, 1, 3, 4, 5, 1, 3, 3, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 3, 4, 5, 2, 5, 1, 2, 5, 5, 1, 2, 3, 5, 1, 2, 3, 5, 1, 2, 3, 4, 3, 5, 5, 2, 1, 5, 1, 2, 3, 4, 5, 1, 2, 4, 5, 1, 1, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 4, 5, 1, 3, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 4, 5, 3, 1, 5, 2, 4, 2, 3, 4, 1, 2, 3, 4, 5, 2, 3, 1, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 4, 5, 2, 4, 5, 1, 2, 4, 5, 4, 1, 2, 3, 4, 5, 5, 1, 3, 4, 5, 1, 3, 4, 2, 1, 2, 3, 4, 5, 3, 3, 1, 3, 5, 1, 2, 3, 5, 2, 3, 4, 5, 4, 5, 5, 4, 5, 3, 1, 2, 4, 5, 2, 1, 2, 3, 5, 1, 3, 1, 4, 5, 3, 3, 4, 1, 3, 1, 2, 3, 4, 4, 5, 3, 5, 1, 1, 2, 4, 5, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 5, 3, 1, 2, 3, 5, 1, 2, 4, 5, 3, 4, 1, 2, 4, 5, 1, 4, 1, 1, 2, 3, 4, 5, 4, 1, 2, 3, 5, 4, 5, 2, 4], \"Freq\": [0.7484083605988732, 0.10691548008555331, 0.10691548008555331, 0.8201652578648523, 0.1369148634717871, 0.6845743173589355, 0.1369148634717871, 0.2532466148887794, 0.0844155382962598, 0.5909087680738186, 0.728719953723594, 0.10994175001492965, 0.5497087500746483, 0.3298252500447889, 0.2952693992214697, 0.49211566536911616, 0.07381734980536743, 0.12302891634227904, 0.7305685204471628, 0.8169155824356799, 0.7287279049438826, 0.7261763822152913, 0.800044483909605, 0.13632332945510306, 0.13632332945510306, 0.6816166472755153, 0.24188608096249184, 0.03023576012031148, 0.36282912144373775, 0.36282912144373775, 0.6551150698918663, 0.21837168996395542, 0.5076104021335813, 0.06345130026669767, 0.12690260053339533, 0.12690260053339533, 0.16920346737786046, 0.5021856360783002, 0.10043712721566005, 0.2259835362352351, 0.17576497262740506, 0.816925995986693, 0.15634362176462074, 0.15634362176462074, 0.625374487058483, 0.8150270069371047, 0.1253887702980161, 0.08774720580353627, 0.39486242611591327, 0.26324161741060886, 0.26324161741060886, 0.7261610107102736, 0.2708889650135705, 0.5079168094004447, 0.16930560313348156, 0.033861120626696314, 0.7336728611868301, 0.8264211166830003, 0.23267936709106143, 0.6980381012731842, 0.3784955220694884, 0.13051569726534082, 0.18272197617147717, 0.10441255781227267, 0.20882511562454534, 0.6209984863645464, 0.33119919272775805, 0.041399899090969756, 0.8521860005823747, 0.8000446905448009, 0.3267083377744314, 0.544513896290719, 0.7305946570043544, 0.21920772832177118, 0.6576231849653136, 0.8000402322699885, 0.21984248920330524, 0.6595274676099158, 0.7287335236511443, 0.42626488589112177, 0.055256559282182455, 0.08683173601485814, 0.24470761967823657, 0.1815572662128852, 0.8224861520960621, 0.3679063375705236, 0.16555785190673564, 0.404696971327576, 0.055185950635578546, 0.7902639621199278, 0.07902639621199278, 0.11853959431798917, 0.813429044316536, 0.17430622378211486, 0.8000872430330374, 0.6240143435331608, 0.3120071717665804, 0.1563905262606948, 0.781952631303474, 0.21971227510860117, 0.6591368253258035, 0.8000292409398282, 0.8000292100249016, 0.1646828807727991, 0.49404864231839735, 0.06587315230911965, 0.09880972846367947, 0.1646828807727991, 0.2746831803717404, 0.1538225810081746, 0.2746831803717404, 0.09888594493382655, 0.1977718898676531, 0.18271011384561658, 0.7308404553824663, 0.7305546448663737, 0.7287387987747237, 0.7305217206415654, 0.15668618779498536, 0.7834309389749268, 0.7336675523800813, 0.7336719572242321, 0.7336626528372577, 0.6333895261620012, 0.027538675050521787, 0.08261602515156537, 0.2753867505052179, 0.7336728640682252, 0.3301300525934167, 0.5502167543223612, 0.8521861994515444, 0.7292485162456348, 0.726177103521237, 0.43797562889914604, 0.08044450326719009, 0.16088900653438018, 0.178765562815978, 0.1430124502527824, 0.09388900673148864, 0.06259267115432576, 0.1877780134629773, 0.4694450336574433, 0.1877780134629773, 0.8534180128699401, 0.10667725160874252, 0.8432656571314968, 0.02219120150346044, 0.11095600751730221, 0.7632082128889899, 0.15264164257779797, 0.8750596772736144, 0.43193112134033385, 0.2303632647148447, 0.10078392831274456, 0.12957933640210015, 0.10798278033508346, 0.8000234424060104, 0.18254312279162158, 0.7301724911664863, 0.6535499960957415, 0.2376545440348151, 0.05941363600870377, 0.3141280273757912, 0.1998996537845944, 0.142785466988996, 0.2284567471823936, 0.1142283735911968, 0.7305901945661974, 0.1822445607930506, 0.7289782431722024, 0.7305883652505472, 0.18178377058080047, 0.7271350823232019, 0.7287321859169944, 0.852197632912963, 0.12107564777007924, 0.7264538866204755, 0.43636468843050585, 0.10389635438821568, 0.0623378126329294, 0.18701343789878822, 0.20779270877643136, 0.886848596626381, 0.43669595204195055, 0.029774724002860267, 0.16872343601620818, 0.1786483440171616, 0.18857325201811503, 0.9301612823885015, 0.15583616787515733, 0.15583616787515733, 0.6233446715006293, 0.7336728622944069, 0.7787062539549611, 0.19467656348874027, 0.9116665577336083, 0.840492719618637, 0.0560328479745758, 0.0560328479745758, 0.6830011645678663, 0.2732004658271465, 0.16719960561057032, 0.5851986196369962, 0.16719960561057032, 0.7304988587168926, 0.6758969468312699, 0.22529898227708994, 0.056324745569272486, 0.7261826139823139, 0.8201669449121054, 0.7261744370276348, 0.7276882179152857, 0.12128136965254763, 0.30466227181321237, 0.21761590843800882, 0.34818545350081415, 0.1305695450628053, 0.7305752026222266, 0.5690135212604996, 0.19870313440842843, 0.0812876458943571, 0.06322372458449996, 0.09935156720421422, 0.7305924076560214, 0.8000255333341603, 0.8535111901454866, 0.10668889876818582, 0.531756843113933, 0.17725228103797766, 0.023633637471730355, 0.2717868309248991, 0.7287335225658355, 0.40478754868264943, 0.32383003894611956, 0.10794334631537318, 0.16191501947305978, 0.34299896720508544, 0.17149948360254272, 0.45733195627344725, 0.2521694890726365, 0.47912202923800934, 0.22695254016537283, 0.0504338978145273, 0.882145825905452, 0.21811213110832922, 0.043622426221665844, 0.17448970488666338, 0.5234691146599901, 0.37902149797670004, 0.24365667727073573, 0.27072964141192857, 0.08121889242357858, 0.5047157701707061, 0.08411929502845102, 0.25235788508535306, 0.08411929502845102, 0.7336712299280149, 0.7261744415111195, 0.8201669449013023, 0.5100228357635427, 0.09808131456991205, 0.1961626291398241, 0.1765463662258417, 0.01961626291398241, 0.16091593171029642, 0.23243412358153925, 0.10727728780686427, 0.41122960325964636, 0.07151819187124285, 0.41420467931606497, 0.1294389622862703, 0.16568187172642598, 0.2019247811665817, 0.08801849435466381, 0.7261715743517693, 0.425883334738151, 0.3484500011493963, 0.19358333397188682, 0.34840675400588234, 0.14048659435721061, 0.19668123210009486, 0.16296444945436434, 0.15172552190578747, 0.18178697334216293, 0.12119131556144194, 0.18178697334216293, 0.48476526224576777, 0.4691472250322285, 0.08529949546040519, 0.18481557349754457, 0.18481557349754457, 0.07108291288367098, 0.2721079849018492, 0.11204446437134966, 0.30412068900794903, 0.14405716847744957, 0.1600635205304995, 0.27493120519347913, 0.6873280129836978, 0.6743220029576661, 0.312490684297455, 0.66080440951457, 0.22026813650485666, 0.7261401828576232, 0.7336728656702144, 0.733520213821335, 0.47932962821832037, 0.14979050881822512, 0.029958101763645023, 0.2696229158728052, 0.059916203527290046, 0.7261789252963998, 0.8868531830419668, 0.7305924156183828, 0.7287204960636828, 0.12150014961290106, 0.8505010472903075, 0.8303651620851198, 0.11862359458358854, 0.42567410485225676, 0.09674411473914926, 0.34827881306093733, 0.03869764589565971, 0.09674411473914926, 0.2994586615548231, 0.14972933077741155, 0.18716166347176444, 0.037432332694352886, 0.2994586615548231, 0.21662877244964868, 0.6498863173489461, 0.29912852384383964, 0.14956426192191982, 0.11217319644143987, 0.07478213096095991, 0.33651958932431963, 0.4227939295974288, 0.2670277450089024, 0.0890092483363008, 0.0445046241681504, 0.1780184966726016, 0.180652789841931, 0.722611159367724, 0.24327091908242499, 0.48654183816484997, 0.24327091908242499, 0.4403609126595461, 0.018348371360814422, 0.22018045632977304, 0.31192231313384516, 0.018348371360814422, 0.272006155777806, 0.6346810301482141, 0.09066871859260202, 0.0946991317675676, 0.5681947906054056, 0.1420486976513514, 0.1893982635351352, 0.2296682809941207, 0.057417070248530176, 0.2870853512426509, 0.40191949173971125, 0.23307392581590297, 0.07769130860530099, 0.15538261721060198, 0.543839160237107, 0.8521790600334113, 0.8264169899671245, 0.7336728581661457, 0.47642728522692135, 0.050150240550202244, 0.050150240550202244, 0.025075120275101122, 0.37612680412651683, 0.7261702763548425, 0.21823025547422795, 0.14548683698281864, 0.4364605109484559, 0.07274341849140932, 0.07274341849140932, 0.3319346588436952, 0.06638693176873904, 0.11064488628123174, 0.13277386353747808, 0.35406363609994157, 0.3696821766333151, 0.14787287065332602, 0.27110026286443106, 0.07393643532666301, 0.14787287065332602, 0.7836697617421241, 0.15673395234842483, 0.28842810083233206, 0.18858760439037095, 0.2995214893258833, 0.07765371945485863, 0.14421405041616603, 0.1371515793837188, 0.5486063175348752, 0.1371515793837188, 0.18286877251162506, 0.1724428197879411, 0.11496187985862741, 0.5173284593638233, 0.22992375971725482, 0.6417656269185397, 0.32088281345926983, 0.09880946757291728, 0.5928568054375037, 0.19761893514583456, 0.7287335239873645, 0.21061817576351285, 0.17551514646959404, 0.17551514646959404, 0.45633938082094455, 0.24468209208506117, 0.2990558903261859, 0.2718689912056235, 0.19030829384393647, 0.6632946307193236, 0.25511331950743216, 0.05102266390148644, 0.05102266390148644, 0.6602986252072615, 0.2200995417357538, 0.7288158657605041, 0.7262445488274626, 0.21731036870855708, 0.6519311061256713, 0.5704916241781718, 0.2181291504210657, 0.03355833083401011, 0.05033749625101516, 0.13423332333604043, 0.8868687418657235, 0.545849559373434, 0.1091699118746868, 0.2183398237493736, 0.8000333562910733, 0.7539394403447558, 0.06282828669539632, 0.12565657339079264, 0.4140771540516411, 0.1936812494757676, 0.22707456835089992, 0.06678663775026468, 0.10017995662539703, 0.7335826039853806, 0.23407417055672347, 0.42558940101222453, 0.06383841015183368, 0.19151523045550103, 0.10639735025305613, 0.34080731334222586, 0.06196496606222288, 0.18589489818666866, 0.4027722794044487, 0.5403182717792431, 0.31628386640736184, 0.059303224951380344, 0.0856602138186605, 0.7997738152308341, 0.06664781793590284, 0.06664781793590284, 0.17491956160638228, 0.3887101369030717, 0.09717753422576793, 0.17491956160638228, 0.17491956160638228, 0.7305526379978186, 0.34498176509030337, 0.3636294280681576, 0.08391448340034406, 0.037295325955708475, 0.16782896680068812, 0.43824813775480076, 0.013695254304837524, 0.1643430516580503, 0.19173356026772534, 0.20542881457256287, 0.728743015436553, 0.7683452710287342, 0.10976361014696204, 0.7336728532516339, 0.3094013370428291, 0.6188026740856583, 0.5104366381724138, 0.5104366381724138, 0.32320399946023914, 0.5171263991363826, 0.12928159978409565, 0.3360051430915208, 0.051693098937157046, 0.2326189452172067, 0.1292327473428926, 0.2326189452172067, 0.546706677374521, 0.2733533386872605, 0.8000675470721756, 0.21812670186805108, 0.17450136149444087, 0.17450136149444087, 0.43625340373610216, 0.5000279232032595, 0.07895177734788308, 0.1842208138117272, 0.15790355469576617, 0.07895177734788308, 0.11458902262032977, 0.5729451131016489, 0.17188353393049466, 0.17188353393049466, 0.09969804125329343, 0.5981882475197605, 0.348943144386527, 0.800058389476849, 0.07306131059948093, 0.4383678635968855, 0.4383678635968855, 0.730590941420069, 0.36202912890684447, 0.04525364111335556, 0.36202912890684447, 0.18101456445342223, 0.04525364111335556, 0.7287335232895397, 0.3182149198675222, 0.21214327991168147, 0.21214327991168147, 0.23866118990064164, 0.10984948517908018, 0.6590969110744811, 0.10984948517908018, 0.8169389499165085, 0.560607111726261, 0.23358629655260876, 0.04671725931052175, 0.04671725931052175, 0.11679314827630438, 0.7336206466075361, 0.7336142580674121, 0.7289854551873393, 0.04859903034582262, 0.1943961213832905, 0.14816750424199357, 0.7408375212099678, 0.04938916808066452, 0.04938916808066452, 0.06124325241273863, 0.7349190289528635, 0.06124325241273863, 0.12248650482547727, 0.8777368248972509, 0.9378201748717129, 0.7286564862687979, 0.7835477755150654, 0.15670955510301307, 0.8264272120229379, 0.6084503400529593, 0.17895598236851745, 0.17895598236851745, 0.03579119647370349, 0.7261685706400053, 0.19960829624465132, 0.48793139082025877, 0.1330721974964342, 0.19960829624465132, 0.2186250471569878, 0.6558751414709634, 0.04572528035581954, 0.8687803267605712, 0.09145056071163908, 0.733672855246794, 0.733672861649093, 0.7305772737116266, 0.31112623807146705, 0.6222524761429341, 0.25649517828702, 0.25649517828702, 0.44886656200228503, 0.064123794571755, 0.8233336900020334, 0.09148152111133705, 0.7336416180015091, 0.7287335242076556, 0.8001117744230392, 0.551301612473796, 0.3772063664294394, 0.029015874340726108, 0.058031748681452215, 0.19974805920105618, 0.49937014800264046, 0.19974805920105618, 0.1558643503201902, 0.19483043790023774, 0.11689826274014264, 0.35069478822042793, 0.1558643503201902, 0.7336617438382739, 0.1884042442480245, 0.23027185408091883, 0.125602829498683, 0.08373521966578866, 0.376808488496049, 0.4103959366678834, 0.03283167493343067, 0.21340588706729935, 0.2298217245340147, 0.1094389164447689, 0.7287928936215384, 0.3093838914532745, 0.618767782906549, 0.9194045452469062, 0.35399042397209035, 0.09439744639255743, 0.35399042397209035, 0.18879489278511485, 0.14680953083091583, 0.6166000294898465, 0.0880857184985495, 0.11744762466473266, 0.7336430848844295, 0.9409126030366174, 0.2713735935200832, 0.2713735935200832, 0.3799230309281165, 0.05427471870401664, 0.8016894608693947, 0.13361491014489912, 0.8000460974013582, 0.558707434588432, 0.14485007563403793, 0.10346433973859852, 0.10346433973859852, 0.08277147179087882, 0.7305873550947813, 0.2767434650864428, 0.2075575988148321, 0.023061955423870233, 0.4843010639012749, 0.3129484359524242, 0.6258968719048484, 0.8169241273900357, 0.7305909332395898], \"Term\": [\"absolutely\", \"absolutely\", \"absolutely\", \"accord\", \"addition\", \"addition\", \"addition\", \"adorable\", \"adorable\", \"adorable\", \"apparent\", \"appear\", \"appear\", \"appear\", \"arm\", \"arm\", \"arm\", \"arm\", \"armhole\", \"armpit\", \"attention\", \"attractive\", \"available\", \"basic\", \"basic\", \"basic\", \"beautiful\", \"beautiful\", \"beautiful\", \"beautiful\", \"belt\", \"belt\", \"big\", \"big\", \"big\", \"big\", \"big\", \"bit\", \"bit\", \"bit\", \"bit\", \"blah\", \"blend\", \"blend\", \"blend\", \"blouse\", \"blouse\", \"blue\", \"blue\", \"blue\", \"blue\", \"boat\", \"boxy\", \"boxy\", \"boxy\", \"boxy\", \"bralette\", \"bum\", \"bust\", \"bust\", \"buy\", \"buy\", \"buy\", \"buy\", \"buy\", \"casual\", \"casual\", \"casual\", \"chance\", \"change\", \"cheap\", \"cheap\", \"chic\", \"classic\", \"classic\", \"classy\", \"clingy\", \"clingy\", \"clothe\", \"color\", \"color\", \"color\", \"color\", \"color\", \"combination\", \"comfortable\", \"comfortable\", \"comfortable\", \"comfortable\", \"comfy\", \"comfy\", \"comfy\", \"compliment\", \"compliment\", \"concerned\", \"cool\", \"cool\", \"couple\", \"couple\", \"crop\", \"crop\", \"cross\", \"currently\", \"cut\", \"cut\", \"cut\", \"cut\", \"cut\", \"cute\", \"cute\", \"cute\", \"cute\", \"cute\", \"daughter\", \"daughter\", \"decent\", \"deep\", \"deliver\", \"denim\", \"denim\", \"detailing\", \"dislike\", \"doll\", \"dress\", \"dress\", \"dress\", \"dress\", \"dressing\", \"edge\", \"edge\", \"errand\", \"event\", \"exchange\", \"fabric\", \"fabric\", \"fabric\", \"fabric\", \"fabric\", \"fall\", \"fall\", \"fall\", \"fall\", \"fall\", \"favorite\", \"favorite\", \"feel\", \"feel\", \"feel\", \"feminine\", \"feminine\", \"finally\", \"fit\", \"fit\", \"fit\", \"fit\", \"fit\", \"fix\", \"flat\", \"flat\", \"flatter\", \"flatter\", \"flatter\", \"flattering\", \"flattering\", \"flattering\", \"flattering\", \"flattering\", \"flaw\", \"flow\", \"flow\", \"follow\", \"forward\", \"forward\", \"gal\", \"generous\", \"girl\", \"girl\", \"good\", \"good\", \"good\", \"good\", \"good\", \"gorgeous\", \"great\", \"great\", \"great\", \"great\", \"great\", \"grey\", \"half\", \"half\", \"half\", \"happen\", \"happy\", \"happy\", \"hard\", \"high\", \"high\", \"high\", \"hold\", \"hold\", \"hole\", \"hole\", \"hole\", \"holiday\", \"hope\", \"hope\", \"hope\", \"hopefully\", \"inch\", \"instantly\", \"issue\", \"issue\", \"jean\", \"jean\", \"jean\", \"jean\", \"jegging\", \"just\", \"just\", \"just\", \"just\", \"just\", \"justice\", \"keeper\", \"knit\", \"knit\", \"large\", \"large\", \"large\", \"large\", \"laugh\", \"lbs\", \"lbs\", \"lbs\", \"lbs\", \"legging\", \"legging\", \"legging\", \"length\", \"length\", \"length\", \"length\", \"lie\", \"light\", \"light\", \"light\", \"light\", \"like\", \"like\", \"like\", \"like\", \"line\", \"line\", \"line\", \"line\", \"lint\", \"listen\", \"literally\", \"little\", \"little\", \"little\", \"little\", \"little\", \"long\", \"long\", \"long\", \"long\", \"long\", \"look\", \"look\", \"look\", \"look\", \"look\", \"lose\", \"lot\", \"lot\", \"lot\", \"love\", \"love\", \"love\", \"love\", \"love\", \"low\", \"low\", \"low\", \"low\", \"make\", \"make\", \"make\", \"make\", \"make\", \"material\", \"material\", \"material\", \"material\", \"material\", \"med\", \"med\", \"medium\", \"medium\", \"middle\", \"middle\", \"midsection\", \"minute\", \"miss\", \"model\", \"model\", \"model\", \"model\", \"model\", \"modern\", \"moss\", \"movement\", \"nearly\", \"neutral\", \"neutral\", \"new\", \"new\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"normally\", \"normally\", \"normally\", \"normally\", \"normally\", \"notice\", \"notice\", \"online\", \"online\", \"online\", \"online\", \"online\", \"order\", \"order\", \"order\", \"order\", \"order\", \"pattern\", \"pattern\", \"people\", \"people\", \"people\", \"perfect\", \"perfect\", \"perfect\", \"perfect\", \"perfect\", \"pic\", \"pic\", \"pic\", \"picture\", \"picture\", \"picture\", \"picture\", \"piece\", \"piece\", \"piece\", \"piece\", \"pink\", \"pink\", \"pink\", \"pink\", \"plain\", \"plenty\", \"postpartum\", \"pretty\", \"pretty\", \"pretty\", \"pretty\", \"pretty\", \"prevent\", \"price\", \"price\", \"price\", \"price\", \"price\", \"purchase\", \"purchase\", \"purchase\", \"purchase\", \"purchase\", \"quality\", \"quality\", \"quality\", \"quality\", \"quality\", \"raw\", \"raw\", \"really\", \"really\", \"really\", \"really\", \"really\", \"receive\", \"receive\", \"receive\", \"receive\", \"red\", \"red\", \"red\", \"red\", \"reference\", \"reference\", \"regular\", \"regular\", \"regular\", \"rest\", \"retailer\", \"retailer\", \"retailer\", \"retailer\", \"return\", \"return\", \"return\", \"return\", \"reviewer\", \"reviewer\", \"reviewer\", \"reviewer\", \"rib\", \"rib\", \"rich\", \"ridiculously\", \"rise\", \"rise\", \"run\", \"run\", \"run\", \"run\", \"run\", \"second\", \"sell\", \"sell\", \"sell\", \"sexy\", \"shape\", \"shape\", \"shape\", \"shirt\", \"shirt\", \"shirt\", \"shirt\", \"shirt\", \"shopping\", \"short\", \"short\", \"short\", \"short\", \"short\", \"shoulder\", \"shoulder\", \"shoulder\", \"shoulder\", \"size\", \"size\", \"size\", \"size\", \"skirt\", \"skirt\", \"skirt\", \"sleeve\", \"sleeve\", \"sleeve\", \"sleeve\", \"sleeve\", \"slit\", \"small\", \"small\", \"small\", \"small\", \"small\", \"soft\", \"soft\", \"soft\", \"soft\", \"soft\", \"softness\", \"spring\", \"spring\", \"statement\", \"strap\", \"strap\", \"stretch\", \"stretch\", \"stripe\", \"stripe\", \"stripe\", \"style\", \"style\", \"style\", \"style\", \"style\", \"substantial\", \"substantial\", \"subtle\", \"summer\", \"summer\", \"summer\", \"summer\", \"super\", \"super\", \"super\", \"super\", \"super\", \"sure\", \"sure\", \"sure\", \"sure\", \"sweater\", \"sweater\", \"sweater\", \"tailor\", \"tall\", \"tall\", \"tall\", \"tan\", \"tank\", \"tank\", \"tank\", \"tank\", \"tank\", \"teal\", \"tee\", \"tee\", \"tee\", \"tee\", \"texture\", \"texture\", \"texture\", \"thank\", \"think\", \"think\", \"think\", \"think\", \"think\", \"thread\", \"thrill\", \"tie\", \"tie\", \"tie\", \"tight\", \"tight\", \"tight\", \"tight\", \"time\", \"time\", \"time\", \"time\", \"ton\", \"tone\", \"totally\", \"transition\", \"transition\", \"trend\", \"true\", \"true\", \"true\", \"true\", \"truly\", \"try\", \"try\", \"try\", \"try\", \"tummy\", \"tummy\", \"tunic\", \"tunic\", \"tunic\", \"turquoise\", \"unexpected\", \"unfinished\", \"use\", \"use\", \"ve\", \"ve\", \"ve\", \"ve\", \"versatile\", \"versatile\", \"vibrant\", \"visual\", \"waiste\", \"want\", \"want\", \"want\", \"want\", \"warm\", \"warm\", \"warm\", \"wash\", \"wash\", \"wash\", \"wash\", \"wash\", \"washer\", \"way\", \"way\", \"way\", \"way\", \"way\", \"wear\", \"wear\", \"wear\", \"wear\", \"wear\", \"wedge\", \"week\", \"week\", \"weekend\", \"white\", \"white\", \"white\", \"white\", \"wide\", \"wide\", \"wide\", \"wide\", \"wine\", \"winter\", \"wish\", \"wish\", \"wish\", \"wish\", \"woman\", \"woman\", \"wonderfully\", \"work\", \"work\", \"work\", \"work\", \"work\", \"xl\", \"xs\", \"xs\", \"xs\", \"xs\", \"year\", \"year\", \"yesterday\", \"zipper\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 1, 4, 2, 5]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el486651406216594172807927377096\", ldavis_el486651406216594172807927377096_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el486651406216594172807927377096\", ldavis_el486651406216594172807927377096_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el486651406216594172807927377096\", ldavis_el486651406216594172807927377096_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=                x           y  topics  cluster       Freq\n",
       "topic                                                    \n",
       "2      150.222153  -72.269554       1        1  37.580666\n",
       "0       51.163364 -159.968018       2        1  16.135227\n",
       "3      -73.144554   21.523815       3        1  15.626008\n",
       "1      -66.410133 -110.606438       4        1  15.416619\n",
       "4       54.417324   12.443444       5        1  15.241480, topic_info=         Term        Freq       Total Category  logprob  loglift\n",
       "523      size  151.000000  151.000000  Default  30.0000  30.0000\n",
       "675      wear  182.000000  182.000000  Default  29.0000  29.0000\n",
       "353    medium   60.000000   60.000000  Default  28.0000  28.0000\n",
       "537     small  107.000000  107.000000  Default  27.0000  27.0000\n",
       "308     large   84.000000   84.000000  Default  26.0000  26.0000\n",
       "..        ...         ...         ...      ...      ...      ...\n",
       "568     style    9.078336   38.689884   Topic5  -4.9657   0.4315\n",
       "523      size   12.558704  151.762404   Topic5  -4.6412  -0.6108\n",
       "247      good    9.561052   48.124884   Topic5  -4.9139   0.2650\n",
       "299      just   11.300970  110.717931   Topic5  -4.7467  -0.4009\n",
       "347  material   10.010703   62.475197   Topic5  -4.8679   0.0500\n",
       "\n",
       "[366 rows x 6 columns], token_table=      Topic      Freq        Term\n",
       "term                             \n",
       "1         1  0.748408  absolutely\n",
       "1         3  0.106915  absolutely\n",
       "1         4  0.106915  absolutely\n",
       "4         5  0.820165      accord\n",
       "8         1  0.136915    addition\n",
       "...     ...       ...         ...\n",
       "702       5  0.484301          xs\n",
       "705       4  0.312948        year\n",
       "705       5  0.625897        year\n",
       "707       2  0.816924   yesterday\n",
       "708       4  0.730591      zipper\n",
       "\n",
       "[644 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[3, 1, 4, 2, 5])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "panel = pyLDAvis.sklearn.prepare(best_lda_model, data_vectorized, vectorizer, mds='tsne')\n",
    "panel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f1c7f6",
   "metadata": {},
   "source": [
    "### plotting words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "4324e53f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-201-e6da9ab02c51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcommon_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_top_n_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommon_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'unigram'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-201-e6da9ab02c51>\u001b[0m in \u001b[0;36mget_top_n_words\u001b[0;34m(corpus, n)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_top_n_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mbag_of_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msum_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbag_of_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mwords_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \"\"\"\n\u001b[1;32m   1168\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_for_unused_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[1;32m   1203\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \"\"\"\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "def get_top_n_words(corpus, n=None):\n",
    "    vec = CountVectorizer(stop_words='english').fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "\n",
    "\n",
    "common_words = get_top_n_words(corpus, 30)\n",
    "df2 = pd.DataFrame(common_words, columns = ['unigram' , 'count'])\n",
    "\n",
    "fig = go.Figure([go.Bar(x=df2['unigram'], y=df2['count'])])\n",
    "fig.update_layout(title=go.layout.Title(text=\"Top 30 unigrams in the question text after removing stop words and lemmatization\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762f9f20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
