{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17a306a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7904f102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import string\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1134b467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9a6ea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b170e15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main df and clean df shape: (23486, 11) (22641, 11)\n",
      "X.shape: (22641,) \t y_shape: (22641, 1)\n",
      "train_test_split: (15848,) (6793,) \t (15848, 1) (6793, 1)\n"
     ]
    }
   ],
   "source": [
    "# Preparing the main corpus\n",
    "main_df= pd.read_csv('data/reviews.csv')\n",
    "\n",
    "# Remove nan reviews\n",
    "df= main_df.copy()\n",
    "df.dropna(subset= ['Review Text'], inplace= True)\n",
    "\n",
    "print('main df and clean df shape:',main_df.shape , df.shape)\n",
    "\n",
    "# X , y\n",
    "\n",
    "X = df['Review Text']\n",
    "y= df[\"Recommended IND\"].values.reshape(-1,1)\n",
    "print(\"X.shape:\", X.shape, '\\t y_shape:', y.shape)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X , y , stratify =y , test_size = 0.3)\n",
    "print('train_test_split:',X_train.shape , X_test.shape,'\\t', y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da78ffdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time takes to convert text input into feature vector:  0.04  mins\n"
     ]
    }
   ],
   "source": [
    "# create countvectorizer:\n",
    "start_time = time.time()\n",
    "\n",
    "cv = CountVectorizer(binary = True, stop_words= 'english',  min_df = 5, max_df = 0.95, ngram_range=(1,2))\n",
    "cv.fit_transform(X_train)\n",
    "train_feature_set = cv.transform(X_train)\n",
    "test_feature_set = cv.transform(X_test)\n",
    "\n",
    "print(\"Time takes to convert text input into feature vector: \", round((time.time() - start_time)/60, 2), \" mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d8175059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15848, 15220)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bd0c39e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[ 730  500]\n",
      " [ 278 5285]]\n",
      "Accuracy:  0.885\n",
      "F1:  0.931\n",
      "Recall:  0.95\n",
      "percision:  0.914\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.59      0.65      1230\n",
      "           1       0.91      0.95      0.93      5563\n",
      "\n",
      "    accuracy                           0.89      6793\n",
      "   macro avg       0.82      0.77      0.79      6793\n",
      "weighted avg       0.88      0.89      0.88      6793\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Logistic regression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train_feature_set,y_train)\n",
    "y_pred = lr.predict(test_feature_set)\n",
    "\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion Matrix:\\n', cm)\n",
    "print(\"Accuracy: \",round(accuracy_score(y_test,y_pred),3))\n",
    "print(\"F1: \",round(f1_score(y_test, y_pred),3))\n",
    "print(\"Recall: \",round(recall_score(y_test,y_pred),3))\n",
    "print(\"percision: \",round(precision_score(y_test, y_pred),3))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1e5cfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predictions(model_name, X_train,y_train,X_test, y_test):\n",
    "    \n",
    "    model = model_name\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(model_name)\n",
    "    acc = cross_val_score(model, X_train, y_train, scoring = \"accuracy\", cv = 5)\n",
    "    predictions = cross_val_predict(model, X_test, y_test, cv = 5)\n",
    "    print(\"Accuracy:\", round(acc.mean(),3))\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    print(\"Confusion Matrix:  \\n\", cm)\n",
    "    print(\"Classification Report \\n\", classification_report( y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "08128b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "Accuracy: 0.886\n",
      "Confusion Matrix:  \n",
      " [[ 653  577]\n",
      " [ 284 5279]]\n",
      "Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.53      0.60      1230\n",
      "           1       0.90      0.95      0.92      5563\n",
      "\n",
      "    accuracy                           0.87      6793\n",
      "   macro avg       0.80      0.74      0.76      6793\n",
      "weighted avg       0.86      0.87      0.87      6793\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logistic regresion\n",
    "lr = LogisticRegression()\n",
    "model_predictions(lr,train_feature_set,y_train, test_feature_set, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6b8760b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier()\n",
      "Accuracy: 0.861\n",
      "Confusion Matrix:  \n",
      " [[ 275  955]\n",
      " [  66 5497]]\n",
      "Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.22      0.35      1230\n",
      "           1       0.85      0.99      0.92      5563\n",
      "\n",
      "    accuracy                           0.85      6793\n",
      "   macro avg       0.83      0.61      0.63      6793\n",
      "weighted avg       0.84      0.85      0.81      6793\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest:\n",
    "rf = RandomForestClassifier()\n",
    "model_predictions(rf,train_feature_set,y_train, test_feature_set, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1e87d2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n",
      "Accuracy: 0.801\n",
      "Confusion Matrix:  \n",
      " [[ 265  965]\n",
      " [ 312 5251]]\n",
      "Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.22      0.29      1230\n",
      "           1       0.84      0.94      0.89      5563\n",
      "\n",
      "    accuracy                           0.81      6793\n",
      "   macro avg       0.65      0.58      0.59      6793\n",
      "weighted avg       0.77      0.81      0.78      6793\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naieve Bayes\n",
    "gnb = GaussianNB()\n",
    "model_predictions(gnb,train_feature_set.toarray(),y_train, test_feature_set.toarray(), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e4d040d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:44:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "[16:56:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:04:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:12:32] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:22:26] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:32:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:41:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:44:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:55:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 0.877\n",
      "Confusion Matrix:  \n",
      " [[ 603  627]\n",
      " [ 196 5367]]\n",
      "Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.49      0.59      1230\n",
      "           1       0.90      0.96      0.93      5563\n",
      "\n",
      "    accuracy                           0.88      6793\n",
      "   macro avg       0.83      0.73      0.76      6793\n",
      "weighted avg       0.87      0.88      0.87      6793\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## XG Boost\n",
    "xgb = XGBClassifier()\n",
    "model_predictions(xgb,train_feature_set.toarray(),y_train, test_feature_set.toarray(), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90a6a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "## same with TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bdc5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = set(string.punctuation)\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "remove_sw_list=['not', 'no']\n",
    "sw = [i for i in stopwords.words('english') if i not in remove_sw_list]\n",
    "\n",
    "def text_prep_stop_stem(text):\n",
    "    #clean text\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    \n",
    "    #remove non-letters and lower case\n",
    "    text = re.sub('[^a-z\\s]', '', text.lower())\n",
    "    \n",
    "    #remove punctuation        \n",
    "    punc_removed = [char for char in text if char not in punct]\n",
    "    punc_removed = ''.join(punc_removed)\n",
    "    \n",
    "    #stem and remove stop words\n",
    "    return [ps.stem(word) for word in punc_removed.split() if not word in sw]\n",
    "    #return [word for word in punc_removed.split() if not word in sw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dff0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tfidf vectorizer:\n",
    "start_time = time.time()\n",
    "\n",
    "tv = TfidfVectorizerianalyzer=orizer(analyzer= text_prep_stop_stem,  min_df = 5, max_df = 0.95, ngram_range=(1,2))\n",
    "cv.fit_transform(X_train)\n",
    "train_feature_set = cv.transform(X_train)\n",
    "test_feature_set = cv.transform(X_test)\n",
    "\n",
    "print(\"Time takes to convert text input into feature vector: \", round((time.time() - start_time)/60, 2), \" mins\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
